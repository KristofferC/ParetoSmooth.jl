{
    "sourceFile": "src/Bootstrap.jl",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 91,
            "patches": [
                {
                    "date": 1627341840659,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                },
                {
                    "date": 1627341992629,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -122,27 +122,27 @@\n \n     # create table with the right labels\n     table = KeyedArray(\n         similar(log_likelihood, 3, 4);\n-        criterion=[:cv_est, :naive_est, :overfit],\n-        statistic=[:ev_total, :se_total, :ev_mean, :se_mean, :sd_mean],\n+        criterion=[:loo_est, :naive_est, :overfit],\n+        statistic=[:total, :se_total, :mean, :se_mean],\n     )\n-    \n+\n     # calculate the sample expectation for the total score\n-    to_sum = pointwise([:loo_est, :naive_est])\n-    @tullio total[crit] := to_sum[data, crit]\n-    table(:, :total) .= reshape(total, 3)\n+    to_sum = pointwise([:loo_est, :naive_est, :overfit])\n+    @tullio averages[crit] := to_sum[data, crit] / data_size\n+    averages = reshape(averages, 3)\n+    table(:, :mean) .= averages\n \n     # calculate the sample expectation for the average score\n-    table(:, :mean) .= table(:, :total) ./ data_size\n+    table(:, :total) .= table(:, :mean) .* data_size\n \n     # calculate the sample expectation for the standard error in the totals\n-    @_ table(:, :se_total) .= pointwise([:loo_est, :naive_est, :overfit]) |> \n-        varm(_, table(:, :mean); dims=1) |>\n-        sqrt.(data_size * _) |>\n-        reshape(_, 3)\n+    se_mean = std(to_sum; mean=averages', dims=1) / sqrt(data_size)\n+    se_mean = reshape(se_mean, 3)\n+    table(:, :se_mean) .= se_mean\n \n     # calculate the sample expectation for the standard error in averages\n-    table(:, :se_mean) .= table(:, :se_total) ./ data_size\n+    table(:, :se_total) .= se_mean * data_size\n \n     return table\n end\n"
                },
                {
                    "date": 1627343276236,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -4,9 +4,9 @@\n using LoopVectorization\n using Statistics\n using Tullio\n \n-export bayes_val\n+export bayes_cv\n \n \"\"\"\n     function bayes_cv(\n         log_likelihood::Array{Float} [, args...];\n"
                },
                {
                    "date": 1627343477877,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,6 +1,5 @@\n using AxisKeys\n-using MeasureTheory\n using InteractiveUtils\n using LoopVectorization\n using Statistics\n using Tullio\n"
                },
                {
                    "date": 1627344469795,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,7 +1,8 @@\n using AxisKeys\n using InteractiveUtils\n using LoopVectorization\n+using Random\n using Statistics\n using Tullio\n \n export bayes_cv\n"
                },
                {
                    "date": 1627348019838,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -53,10 +53,11 @@\n     log_count = log(mcmc_count)\n \n \n     # TODO: Add a way of using score functions other than ELPD\n-    bb_weights = data_size * rand(rng, Dirichlet(ones(data_size)), resamples)\n-    bb_samples = similar(log_likelihood, (resamples, data_size))\n+    bb_weights = data_size * rand(rng, Dirichlet(ones(data_size)), resamples) .- 1\n+    @tullio bb_samples[datum, resample] := \n+        bb_weights[datum, resample] * log_likelihood[datum, step, chain]\n     psis_object = psis(bb_samples, args...; kwargs...)\n \n     # \"Pointwise\" used here to refer to \"per resample\"\n     @tullio pointwise_naive[i] := log <|\n"
                },
                {
                    "date": 1627348744903,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -53,10 +53,10 @@\n     log_count = log(mcmc_count)\n \n \n     # TODO: Add a way of using score functions other than ELPD\n-    bb_weights = data_size * rand(rng, Dirichlet(ones(data_size)), resamples) .- 1\n-    @tullio bb_samples[datum, resample] := \n+    bb_weights = rand(rng, Dirichlet(ones(data_size)), resamples)\n+    @tullio bb_samples[resample] := data_size *\n         bb_weights[datum, resample] * log_likelihood[datum, step, chain]\n     psis_object = psis(bb_samples, args...; kwargs...)\n \n     # \"Pointwise\" used here to refer to \"per resample\"\n"
                },
                {
                    "date": 1627348769562,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -54,9 +54,9 @@\n \n \n     # TODO: Add a way of using score functions other than ELPD\n     bb_weights = rand(rng, Dirichlet(ones(data_size)), resamples)\n-    @tullio bb_samples[resample] := data_size *\n+    @tullio bb_samples[resample, step, chain] := data_size *\n         bb_weights[datum, resample] * log_likelihood[datum, step, chain]\n     psis_object = psis(bb_samples, args...; kwargs...)\n \n     # \"Pointwise\" used here to refer to \"per resample\"\n"
                },
                {
                    "date": 1627348833888,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -57,12 +57,13 @@\n     bb_weights = rand(rng, Dirichlet(ones(data_size)), resamples)\n     @tullio bb_samples[resample, step, chain] := data_size *\n         bb_weights[datum, resample] * log_likelihood[datum, step, chain]\n     psis_object = psis(bb_samples, args...; kwargs...)\n+    psis_weights = psis_object.weights\n \n     # \"Pointwise\" used here to refer to \"per resample\"\n     @tullio pointwise_naive[i] := log <|\n-        psis_object.weights[i, j, k] * exp(bb_samples[i, j, k])\n+        psis_weights[i, j, k] * exp(bb_samples[i, j, k])\n     @tullio sample_est := exp(log_likelihood[i, j, k] - log_count)\n     sample_est = log(sample_est)\n     \n     @tturbo bb_ests .= (2 * sample_est) .- pointwise_naive\n"
                },
                {
                    "date": 1627348885081,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -65,9 +65,9 @@\n         psis_weights[i, j, k] * exp(bb_samples[i, j, k])\n     @tullio sample_est := exp(log_likelihood[i, j, k] - log_count)\n     sample_est = log(sample_est)\n     \n-    @tturbo bb_ests .= (2 * sample_est) .- pointwise_naive\n+    bb_ests = (2 * sample_est) .- pointwise_naive\n     @tullio pointwise_mcse[i] :=  # I'll take sqrt later in-place\n         (weights[i, j, k] * (log_likelihood[i, j, k] - pointwise_loo[i]))^2\n     # Apply law of total variance\n     bootstrap_se = var(naive_ests) / bb_samples\n"
                },
                {
                    "date": 1627348907033,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -67,9 +67,9 @@\n     sample_est = log(sample_est)\n     \n     bb_ests = (2 * sample_est) .- pointwise_naive\n     @tullio pointwise_mcse[i] :=  # I'll take sqrt later in-place\n-        (weights[i, j, k] * (log_likelihood[i, j, k] - pointwise_loo[i]))^2\n+        (psis_weights[i, j, k] * (log_likelihood[i, j, k] - pointwise_loo[i]))^2\n     # Apply law of total variance\n     bootstrap_se = var(naive_ests) / bb_samples\n     mcse = sqrt(mean(pointwise_mcse) + bootstrap_se)\n     @tturbo @. pointwise_mcse = sqrt(pointwise_mcse)\n"
                },
                {
                    "date": 1627348933652,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -83,9 +83,9 @@\n             pointwise_overfit,\n             pointwise_mcse,\n             psis_object.pareto_k\n         );\n-        data=1:length(pointwise_loo),\n+        data=Base.OneTo(resamples),\n         statistic=[\n             :loo_est,\n             :naive_est,\n             :overfit,\n"
                },
                {
                    "date": 1627348973616,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -60,16 +60,16 @@\n     psis_object = psis(bb_samples, args...; kwargs...)\n     psis_weights = psis_object.weights\n \n     # \"Pointwise\" used here to refer to \"per resample\"\n-    @tullio pointwise_naive[i] := log <|\n+    @tullio resampled_naive[i] := log <|\n         psis_weights[i, j, k] * exp(bb_samples[i, j, k])\n     @tullio sample_est := exp(log_likelihood[i, j, k] - log_count)\n     sample_est = log(sample_est)\n     \n     bb_ests = (2 * sample_est) .- pointwise_naive\n     @tullio pointwise_mcse[i] :=  # I'll take sqrt later in-place\n-        (psis_weights[i, j, k] * (log_likelihood[i, j, k] - pointwise_loo[i]))^2\n+        (psis_weights[i, j, k] * (log_likelihood[i, j, k] - resampled_naive[i]))^2\n     # Apply law of total variance\n     bootstrap_se = var(naive_ests) / bb_samples\n     mcse = sqrt(mean(pointwise_mcse) + bootstrap_se)\n     @tturbo @. pointwise_mcse = sqrt(pointwise_mcse)\n"
                },
                {
                    "date": 1627349070885,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -65,23 +65,22 @@\n         psis_weights[i, j, k] * exp(bb_samples[i, j, k])\n     @tullio sample_est := exp(log_likelihood[i, j, k] - log_count)\n     sample_est = log(sample_est)\n     \n-    bb_ests = (2 * sample_est) .- pointwise_naive\n+    bb_ests = (2 * sample_est) .- resampled_naive\n     @tullio pointwise_mcse[i] :=  # I'll take sqrt later in-place\n         (psis_weights[i, j, k] * (log_likelihood[i, j, k] - resampled_naive[i]))^2\n     # Apply law of total variance\n     bootstrap_se = var(naive_ests) / bb_samples\n     mcse = sqrt(mean(pointwise_mcse) + bootstrap_se)\n     @tturbo @. pointwise_mcse = sqrt(pointwise_mcse)\n         \n     # Posterior for the *average score*, not the mean of the posterior distribution:\n-    posterior_avg = bb_ests / data_size\n     resample_calcs = KeyedArray(\n         hcat(\n             bb_ests,\n-            pointwise_naive,\n-            pointwise_overfit,\n+            resampled_naive,\n+            resampled_naive - bb_ests,\n             pointwise_mcse,\n             psis_object.pareto_k\n         );\n         data=Base.OneTo(resamples),\n"
                },
                {
                    "date": 1627349091014,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -66,22 +66,22 @@\n     @tullio sample_est := exp(log_likelihood[i, j, k] - log_count)\n     sample_est = log(sample_est)\n     \n     bb_ests = (2 * sample_est) .- resampled_naive\n-    @tullio pointwise_mcse[i] :=  # I'll take sqrt later in-place\n+    @tullio mcse[i] :=  # I'll take sqrt later in-place\n         (psis_weights[i, j, k] * (log_likelihood[i, j, k] - resampled_naive[i]))^2\n     # Apply law of total variance\n     bootstrap_se = var(naive_ests) / bb_samples\n-    mcse = sqrt(mean(pointwise_mcse) + bootstrap_se)\n-    @tturbo @. pointwise_mcse = sqrt(pointwise_mcse)\n+    mcse = sqrt(mean(mcse) + bootstrap_se)\n+    @tturbo @. mcse = sqrt(mcse)\n         \n     # Posterior for the *average score*, not the mean of the posterior distribution:\n     resample_calcs = KeyedArray(\n         hcat(\n             bb_ests,\n             resampled_naive,\n             resampled_naive - bb_ests,\n-            pointwise_mcse,\n+            mcse,\n             psis_object.pareto_k\n         );\n         data=Base.OneTo(resamples),\n         statistic=[\n"
                },
                {
                    "date": 1627349339009,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -74,8 +74,12 @@\n     mcse = sqrt(mean(mcse) + bootstrap_se)\n     @tturbo @. mcse = sqrt(mcse)\n         \n     # Posterior for the *average score*, not the mean of the posterior distribution:\n+    println(length(bb_ests))\n+    println(length(resampled_naive))\n+    println(length(mcse))\n+    println(length(psis_object.pareto_k))\n     resample_calcs = KeyedArray(\n         hcat(\n             bb_ests,\n             resampled_naive,\n"
                },
                {
                    "date": 1627349678145,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -60,10 +60,10 @@\n     psis_object = psis(bb_samples, args...; kwargs...)\n     psis_weights = psis_object.weights\n \n     # \"Pointwise\" used here to refer to \"per resample\"\n-    @tullio resampled_naive[i] := log <|\n-        psis_weights[i, j, k] * exp(bb_samples[i, j, k])\n+    @tullio resampled_naive[resample] := log <|\n+        psis_weights[resample, step, chain] * exp(bb_samples[resample, step, chain])\n     @tullio sample_est := exp(log_likelihood[i, j, k] - log_count)\n     sample_est = log(sample_est)\n     \n     bb_ests = (2 * sample_est) .- resampled_naive\n"
                },
                {
                    "date": 1627349856555,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -66,10 +66,10 @@\n     @tullio sample_est := exp(log_likelihood[i, j, k] - log_count)\n     sample_est = log(sample_est)\n     \n     bb_ests = (2 * sample_est) .- resampled_naive\n-    @tullio mcse[i] :=  # I'll take sqrt later in-place\n-        (psis_weights[i, j, k] * (log_likelihood[i, j, k] - resampled_naive[i]))^2\n+    @tullio mcse[resample] :=  # I'll take sqrt later in-place\n+        (psis_weights[resample, step, chain] * (log_likelihood[resample, step, chain] - resampled_naive[resample]))^2\n     # Apply law of total variance\n     bootstrap_se = var(naive_ests) / bb_samples\n     mcse = sqrt(mean(mcse) + bootstrap_se)\n     @tturbo @. mcse = sqrt(mcse)\n"
                },
                {
                    "date": 1627349907598,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -66,8 +66,13 @@\n     @tullio sample_est := exp(log_likelihood[i, j, k] - log_count)\n     sample_est = log(sample_est)\n     \n     bb_ests = (2 * sample_est) .- resampled_naive\n+    display(psis_weights)\n+    println()\n+    display(log_likelihood)\n+    println()\n+    display(resampled_naive)\n     @tullio mcse[resample] :=  # I'll take sqrt later in-place\n         (psis_weights[resample, step, chain] * (log_likelihood[resample, step, chain] - resampled_naive[resample]))^2\n     # Apply law of total variance\n     bootstrap_se = var(naive_ests) / bb_samples\n"
                },
                {
                    "date": 1627351969812,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -74,9 +74,9 @@\n     display(resampled_naive)\n     @tullio mcse[resample] :=  # I'll take sqrt later in-place\n         (psis_weights[resample, step, chain] * (log_likelihood[resample, step, chain] - resampled_naive[resample]))^2\n     # Apply law of total variance\n-    bootstrap_se = var(naive_ests) / bb_samples\n+    bootstrap_se = var(resampled_naive) / bb_samples\n     mcse = sqrt(mean(mcse) + bootstrap_se)\n     @tturbo @. mcse = sqrt(mcse)\n         \n     # Posterior for the *average score*, not the mean of the posterior distribution:\n"
                },
                {
                    "date": 1627404798329,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -54,42 +54,32 @@\n \n \n     # TODO: Add a way of using score functions other than ELPD\n     bb_weights = rand(rng, Dirichlet(ones(data_size)), resamples)\n-    @tullio bb_samples[resample, step, chain] := data_size *\n-        bb_weights[datum, resample] * log_likelihood[datum, step, chain]\n+    @tullio bb_samples[re, step, chain] := \n+        data_size * bb_weights[datum, re] * log_likelihood[datum, step, chain]\n     psis_object = psis(bb_samples, args...; kwargs...)\n     psis_weights = psis_object.weights\n \n-    # \"Pointwise\" used here to refer to \"per resample\"\n-    @tullio resampled_naive[resample] := log <|\n-        psis_weights[resample, step, chain] * exp(bb_samples[resample, step, chain])\n+    @tullio re_naive[re] := log <|\n+        psis_weights[re, step, chain] * exp(bb_samples[re, step, chain] - log_count)\n     @tullio sample_est := exp(log_likelihood[i, j, k] - log_count)\n     sample_est = log(sample_est)\n     \n-    bb_ests = (2 * sample_est) .- resampled_naive\n-    display(psis_weights)\n-    println()\n-    display(log_likelihood)\n-    println()\n-    display(resampled_naive)\n-    @tullio mcse[resample] :=  # I'll take sqrt later in-place\n-        (psis_weights[resample, step, chain] * (log_likelihood[resample, step, chain] - resampled_naive[resample]))^2\n+    bb_ests = (2 * sample_est) .- re_naive\n+    @tullio grad=true mcse[re] := \n+        psis_weights[re, step, chain] * (bb_weights[re, step, chain] - re_naive[re])^2\n     # Apply law of total variance\n-    bootstrap_se = var(resampled_naive) / bb_samples\n+    bootstrap_se = var(re_naive) / bb_samples\n     mcse = sqrt(mean(mcse) + bootstrap_se)\n     @tturbo @. mcse = sqrt(mcse)\n         \n     # Posterior for the *average score*, not the mean of the posterior distribution:\n-    println(length(bb_ests))\n-    println(length(resampled_naive))\n-    println(length(mcse))\n-    println(length(psis_object.pareto_k))\n     resample_calcs = KeyedArray(\n         hcat(\n             bb_ests,\n-            resampled_naive,\n-            resampled_naive - bb_ests,\n+            re_naive,\n+            re_naive - bb_ests,\n             mcse,\n             psis_object.pareto_k\n         );\n         data=Base.OneTo(resamples),\n"
                },
                {
                    "date": 1627493201114,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -59,21 +59,21 @@\n         data_size * bb_weights[datum, re] * log_likelihood[datum, step, chain]\n     psis_object = psis(bb_samples, args...; kwargs...)\n     psis_weights = psis_object.weights\n \n-    @tullio re_naive[re] := log <|\n+    @tullio re_naive[re] := log <| # calculate the naive estimate in many resamples\n         psis_weights[re, step, chain] * exp(bb_samples[re, step, chain] - log_count)\n     @tullio sample_est := exp(log_likelihood[i, j, k] - log_count)\n     sample_est = log(sample_est)\n     \n     bb_ests = (2 * sample_est) .- re_naive\n     @tullio grad=true mcse[re] := \n-        psis_weights[re, step, chain] * (bb_weights[re, step, chain] - re_naive[re])^2\n+        (psis_weights[re, step, chain] * (bb_weights[re, step, chain] - re_naive[re]))^2\n     # Apply law of total variance\n     bootstrap_se = var(re_naive) / bb_samples\n     mcse = sqrt(mean(mcse) + bootstrap_se)\n     @tturbo @. mcse = sqrt(mcse)\n-        \n+\n     # Posterior for the *average score*, not the mean of the posterior distribution:\n     resample_calcs = KeyedArray(\n         hcat(\n             bb_ests,\n"
                },
                {
                    "date": 1627493256746,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -65,9 +65,9 @@\n     @tullio sample_est := exp(log_likelihood[i, j, k] - log_count)\n     sample_est = log(sample_est)\n     \n     bb_ests = (2 * sample_est) .- re_naive\n-    @tullio grad=true mcse[re] := \n+    @tullio mcse[re] := \n         (psis_weights[re, step, chain] * (bb_weights[re, step, chain] - re_naive[re]))^2\n     # Apply law of total variance\n     bootstrap_se = var(re_naive) / bb_samples\n     mcse = sqrt(mean(mcse) + bootstrap_se)\n"
                },
                {
                    "date": 1627494649351,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -66,9 +66,9 @@\n     sample_est = log(sample_est)\n     \n     bb_ests = (2 * sample_est) .- re_naive\n     @tullio mcse[re] := \n-        (psis_weights[re, step, chain] * (bb_weights[re, step, chain] - re_naive[re]))^2\n+        (psis_weights[re, step, chain] * (bb_samples[re, step, chain] - re_naive[re]))^2\n     # Apply law of total variance\n     bootstrap_se = var(re_naive) / bb_samples\n     mcse = sqrt(mean(mcse) + bootstrap_se)\n     @tturbo @. mcse = sqrt(mcse)\n"
                },
                {
                    "date": 1627494725605,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -68,9 +68,9 @@\n     bb_ests = (2 * sample_est) .- re_naive\n     @tullio mcse[re] := \n         (psis_weights[re, step, chain] * (bb_samples[re, step, chain] - re_naive[re]))^2\n     # Apply law of total variance\n-    bootstrap_se = var(re_naive) / bb_samples\n+    bootstrap_se = var(re_naive) / resamples\n     mcse = sqrt(mean(mcse) + bootstrap_se)\n     @tturbo @. mcse = sqrt(mcse)\n \n     # Posterior for the *average score*, not the mean of the posterior distribution:\n"
                },
                {
                    "date": 1627494833582,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -70,9 +70,9 @@\n         (psis_weights[re, step, chain] * (bb_samples[re, step, chain] - re_naive[re]))^2\n     # Apply law of total variance\n     bootstrap_se = var(re_naive) / resamples\n     mcse = sqrt(mean(mcse) + bootstrap_se)\n-    @tturbo @. mcse = sqrt(mcse)\n+    @turbo @. mcse = sqrt(mcse)\n \n     # Posterior for the *average score*, not the mean of the posterior distribution:\n     resample_calcs = KeyedArray(\n         hcat(\n"
                },
                {
                    "date": 1627494841915,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -70,9 +70,8 @@\n         (psis_weights[re, step, chain] * (bb_samples[re, step, chain] - re_naive[re]))^2\n     # Apply law of total variance\n     bootstrap_se = var(re_naive) / resamples\n     mcse = sqrt(mean(mcse) + bootstrap_se)\n-    @turbo @. mcse = sqrt(mcse)\n \n     # Posterior for the *average score*, not the mean of the posterior distribution:\n     resample_calcs = KeyedArray(\n         hcat(\n"
                },
                {
                    "date": 1627494868914,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -69,9 +69,8 @@\n     @tullio mcse[re] := \n         (psis_weights[re, step, chain] * (bb_samples[re, step, chain] - re_naive[re]))^2\n     # Apply law of total variance\n     bootstrap_se = var(re_naive) / resamples\n-    mcse = sqrt(mean(mcse) + bootstrap_se)\n \n     # Posterior for the *average score*, not the mean of the posterior distribution:\n     resample_calcs = KeyedArray(\n         hcat(\n"
                },
                {
                    "date": 1627495778609,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -74,9 +74,9 @@\n     # Posterior for the *average score*, not the mean of the posterior distribution:\n     resample_calcs = KeyedArray(\n         hcat(\n             bb_ests,\n-            re_naive,\n+            - re_naive,\n             re_naive - bb_ests,\n             mcse,\n             psis_object.pareto_k\n         );\n@@ -105,18 +105,18 @@\n     log_likelihood::T,\n     args...;\n     chain_index::AbstractVector=ones(size(log_likelihood, 1)),\n     kwargs...,\n-) where {F <: AbstractFloat, T <: AbstractMatrix{F}}\n+) where {F<:AbstractFloat, T<:AbstractMatrix{F}}\n     new_log_ratios = _convert_to_array(log_likelihood, chain_index)\n     return psis_loo(new_log_ratios, args...; kwargs...)\n end\n \n \n function _generate_bayes_table(\n     log_likelihood::AbstractArray, \n     pointwise::AbstractArray, \n-    data_size::Integer\n+    resamples::Integer\n )\n \n     # create table with the right labels\n     table = KeyedArray(\n@@ -126,9 +126,9 @@\n     )\n \n     # calculate the sample expectation for the total score\n     to_sum = pointwise([:loo_est, :naive_est, :overfit])\n-    @tullio averages[crit] := to_sum[data, crit] / data_size\n+    @tullio averages[crit] := to_sum[re, crit] / resamples\n     averages = reshape(averages, 3)\n     table(:, :mean) .= averages\n \n     # calculate the sample expectation for the average score\n"
                },
                {
                    "date": 1627496041687,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -53,9 +53,9 @@\n     log_count = log(mcmc_count)\n \n \n     # TODO: Add a way of using score functions other than ELPD\n-    bb_weights = rand(rng, Dirichlet(ones(data_size)), resamples)\n+    bb_weights = data_size * rand(rng, Dirichlet(ones(data_size)), resamples) .- 1\n     @tullio bb_samples[re, step, chain] := \n         data_size * bb_weights[datum, re] * log_likelihood[datum, step, chain]\n     psis_object = psis(bb_samples, args...; kwargs...)\n     psis_weights = psis_object.weights\n@@ -114,9 +114,10 @@\n \n function _generate_bayes_table(\n     log_likelihood::AbstractArray, \n     pointwise::AbstractArray, \n-    resamples::Integer\n+    resamples::Integer,\n+    data_size\n )\n \n     # create table with the right labels\n     table = KeyedArray(\n@@ -126,14 +127,14 @@\n     )\n \n     # calculate the sample expectation for the total score\n     to_sum = pointwise([:loo_est, :naive_est, :overfit])\n-    @tullio averages[crit] := to_sum[re, crit] / resamples\n-    averages = reshape(averages, 3)\n-    table(:, :mean) .= averages\n+    @tullio totals[crit] := to_sum[re, crit] / resamples\n+    totals = reshape(totals, 3)\n+    table(:, :total) .= totals\n \n     # calculate the sample expectation for the average score\n-    table(:, :total) .= table(:, :mean) .* data_size\n+    table(:, :total) .= table(:, :mean) / data_size\n \n     # calculate the sample expectation for the standard error in the totals\n     se_mean = std(to_sum; mean=averages', dims=1) / sqrt(data_size)\n     se_mean = reshape(se_mean, 3)\n"
                },
                {
                    "date": 1627496100648,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -53,9 +53,9 @@\n     log_count = log(mcmc_count)\n \n \n     # TODO: Add a way of using score functions other than ELPD\n-    bb_weights = data_size * rand(rng, Dirichlet(ones(data_size)), resamples) .- 1\n+    bb_weights = 1 .- data_size * rand(rng, Dirichlet(ones(data_size)), resamples)\n     @tullio bb_samples[re, step, chain] := \n         data_size * bb_weights[datum, re] * log_likelihood[datum, step, chain]\n     psis_object = psis(bb_samples, args...; kwargs...)\n     psis_weights = psis_object.weights\n"
                },
                {
                    "date": 1627496334614,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -63,9 +63,9 @@\n     @tullio re_naive[re] := log <| # calculate the naive estimate in many resamples\n         psis_weights[re, step, chain] * exp(bb_samples[re, step, chain] - log_count)\n     @tullio sample_est := exp(log_likelihood[i, j, k] - log_count)\n     sample_est = log(sample_est)\n-    \n+\n     bb_ests = (2 * sample_est) .- re_naive\n     @tullio mcse[re] := \n         (psis_weights[re, step, chain] * (bb_samples[re, step, chain] - re_naive[re]))^2\n     # Apply law of total variance\n@@ -74,9 +74,9 @@\n     # Posterior for the *average score*, not the mean of the posterior distribution:\n     resample_calcs = KeyedArray(\n         hcat(\n             bb_ests,\n-            - re_naive,\n+            -re_naive,\n             re_naive - bb_ests,\n             mcse,\n             psis_object.pareto_k\n         );\n"
                },
                {
                    "date": 1627496433721,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -65,9 +65,9 @@\n     @tullio sample_est := exp(log_likelihood[i, j, k] - log_count)\n     sample_est = log(sample_est)\n \n     bb_ests = (2 * sample_est) .- re_naive\n-    @tullio mcse[re] := \n+    @tullio mcse[re] := sqrt <|\n         (psis_weights[re, step, chain] * (bb_samples[re, step, chain] - re_naive[re]))^2\n     # Apply law of total variance\n     bootstrap_se = var(re_naive) / resamples\n \n@@ -89,9 +89,9 @@\n             :pareto_k\n         ],\n     )\n \n-    estimates = _generate_bayes_table(log_likelihood, resample_calcs, data_size)\n+    estimates = _generate_bayes_table(log_likelihood, resample_calcs, resamples, data_size)\n \n     return BayesCV(\n         estimates,\n         resample_calcs,\n@@ -115,9 +115,9 @@\n function _generate_bayes_table(\n     log_likelihood::AbstractArray, \n     pointwise::AbstractArray, \n     resamples::Integer,\n-    data_size\n+    data_size::Integer\n )\n \n     # create table with the right labels\n     table = KeyedArray(\n"
                },
                {
                    "date": 1627496460336,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -67,10 +67,9 @@\n \n     bb_ests = (2 * sample_est) .- re_naive\n     @tullio mcse[re] := sqrt <|\n         (psis_weights[re, step, chain] * (bb_samples[re, step, chain] - re_naive[re]))^2\n-    # Apply law of total variance\n-    bootstrap_se = var(re_naive) / resamples\n+    bootstrap_se = std(re_naive) / resamples\n \n     # Posterior for the *average score*, not the mean of the posterior distribution:\n     resample_calcs = KeyedArray(\n         hcat(\n"
                },
                {
                    "date": 1627496494286,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -63,8 +63,9 @@\n     @tullio re_naive[re] := log <| # calculate the naive estimate in many resamples\n         psis_weights[re, step, chain] * exp(bb_samples[re, step, chain] - log_count)\n     @tullio sample_est := exp(log_likelihood[i, j, k] - log_count)\n     sample_est = log(sample_est)\n+    display(sample_est)\n \n     bb_ests = (2 * sample_est) .- re_naive\n     @tullio mcse[re] := sqrt <|\n         (psis_weights[re, step, chain] * (bb_samples[re, step, chain] - re_naive[re]))^2\n"
                },
                {
                    "date": 1627496687186,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -53,9 +53,9 @@\n     log_count = log(mcmc_count)\n \n \n     # TODO: Add a way of using score functions other than ELPD\n-    bb_weights = 1 .- data_size * rand(rng, Dirichlet(ones(data_size)), resamples)\n+    bb_weights = rand(rng, Dirichlet(ones(data_size)), resamples)\n     @tullio bb_samples[re, step, chain] := \n         data_size * bb_weights[datum, re] * log_likelihood[datum, step, chain]\n     psis_object = psis(bb_samples, args...; kwargs...)\n     psis_weights = psis_object.weights\n"
                },
                {
                    "date": 1627496722932,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -74,9 +74,9 @@\n     # Posterior for the *average score*, not the mean of the posterior distribution:\n     resample_calcs = KeyedArray(\n         hcat(\n             bb_ests,\n-            -re_naive,\n+            re_naive,\n             re_naive - bb_ests,\n             mcse,\n             psis_object.pareto_k\n         );\n@@ -132,9 +132,9 @@\n     totals = reshape(totals, 3)\n     table(:, :total) .= totals\n \n     # calculate the sample expectation for the average score\n-    table(:, :total) .= table(:, :mean) / data_size\n+    table(:, :mean) .= averages = table(:, :total) / data_size\n \n     # calculate the sample expectation for the standard error in the totals\n     se_mean = std(to_sum; mean=averages', dims=1) / sqrt(data_size)\n     se_mean = reshape(se_mean, 3)\n"
                },
                {
                    "date": 1627496729810,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -132,9 +132,9 @@\n     totals = reshape(totals, 3)\n     table(:, :total) .= totals\n \n     # calculate the sample expectation for the average score\n-    table(:, :mean) .= averages = table(:, :total) / data_size\n+    table(:, :mean) .= (averages = table(:, :total) / data_size)\n \n     # calculate the sample expectation for the standard error in the totals\n     se_mean = std(to_sum; mean=averages', dims=1) / sqrt(data_size)\n     se_mean = reshape(se_mean, 3)\n"
                },
                {
                    "date": 1627496809526,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -61,9 +61,10 @@\n     psis_weights = psis_object.weights\n \n     @tullio re_naive[re] := log <| # calculate the naive estimate in many resamples\n         psis_weights[re, step, chain] * exp(bb_samples[re, step, chain] - log_count)\n-    @tullio sample_est := exp(log_likelihood[i, j, k] - log_count)\n+    @tullio sample_est := log <|\n+        exp(bb_samples[re, step, chain] - log_count)\n     sample_est = log(sample_est)\n     display(sample_est)\n \n     bb_ests = (2 * sample_est) .- re_naive\n"
                },
                {
                    "date": 1627497010737,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -53,18 +53,18 @@\n     log_count = log(mcmc_count)\n \n \n     # TODO: Add a way of using score functions other than ELPD\n-    bb_weights = rand(rng, Dirichlet(ones(data_size)), resamples)\n+    bb_weights = 1 .- rand(rng, Dirichlet(ones(data_size)), resamples)\n     @tullio bb_samples[re, step, chain] := \n         data_size * bb_weights[datum, re] * log_likelihood[datum, step, chain]\n     psis_object = psis(bb_samples, args...; kwargs...)\n     psis_weights = psis_object.weights\n \n     @tullio re_naive[re] := log <| # calculate the naive estimate in many resamples\n         psis_weights[re, step, chain] * exp(bb_samples[re, step, chain] - log_count)\n     @tullio sample_est := log <|\n-        exp(bb_samples[re, step, chain] - log_count)\n+        exp([re, step, chain] - log_count)\n     sample_est = log(sample_est)\n     display(sample_est)\n \n     bb_ests = (2 * sample_est) .- re_naive\n"
                },
                {
                    "date": 1627497324182,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -61,10 +61,9 @@\n     psis_weights = psis_object.weights\n \n     @tullio re_naive[re] := log <| # calculate the naive estimate in many resamples\n         psis_weights[re, step, chain] * exp(bb_samples[re, step, chain] - log_count)\n-    @tullio sample_est := log <|\n-        exp([re, step, chain] - log_count)\n+    @tullio sample_est := exp([re, step, chain] - log_count)\n     sample_est = log(sample_est)\n     display(sample_est)\n \n     bb_ests = (2 * sample_est) .- re_naive\n"
                },
                {
                    "date": 1627497456197,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -61,9 +61,9 @@\n     psis_weights = psis_object.weights\n \n     @tullio re_naive[re] := log <| # calculate the naive estimate in many resamples\n         psis_weights[re, step, chain] * exp(bb_samples[re, step, chain] - log_count)\n-    @tullio sample_est := exp([re, step, chain] - log_count)\n+    @tullio sample_est := exp([datum, step, chain] - log_count)\n     sample_est = log(sample_est)\n     display(sample_est)\n \n     bb_ests = (2 * sample_est) .- re_naive\n"
                },
                {
                    "date": 1627497491200,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -62,8 +62,9 @@\n \n     @tullio re_naive[re] := log <| # calculate the naive estimate in many resamples\n         psis_weights[re, step, chain] * exp(bb_samples[re, step, chain] - log_count)\n     @tullio sample_est := exp([datum, step, chain] - log_count)\n+    display(re_naive)\n     sample_est = log(sample_est)\n     display(sample_est)\n \n     bb_ests = (2 * sample_est) .- re_naive\n"
                },
                {
                    "date": 1627497504795,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -60,9 +60,9 @@\n     psis_object = psis(bb_samples, args...; kwargs...)\n     psis_weights = psis_object.weights\n \n     @tullio re_naive[re] := log <| # calculate the naive estimate in many resamples\n-        psis_weights[re, step, chain] * exp(bb_samples[re, step, chain] - log_count)\n+        psis_weights[re, step, chain] * exp(bb_samples[re, step, chain])\n     @tullio sample_est := exp([datum, step, chain] - log_count)\n     display(re_naive)\n     sample_est = log(sample_est)\n     display(sample_est)\n"
                },
                {
                    "date": 1627497529353,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -61,9 +61,9 @@\n     psis_weights = psis_object.weights\n \n     @tullio re_naive[re] := log <| # calculate the naive estimate in many resamples\n         psis_weights[re, step, chain] * exp(bb_samples[re, step, chain])\n-    @tullio sample_est := exp([datum, step, chain] - log_count)\n+    @tullio sample_est := exp(log_likelihood[datum, step, chain] - log_count)\n     display(re_naive)\n     sample_est = log(sample_est)\n     display(sample_est)\n \n"
                },
                {
                    "date": 1627497562909,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -53,9 +53,9 @@\n     log_count = log(mcmc_count)\n \n \n     # TODO: Add a way of using score functions other than ELPD\n-    bb_weights = 1 .- rand(rng, Dirichlet(ones(data_size)), resamples)\n+    bb_weights = rand(rng, Dirichlet(ones(data_size)), resamples)\n     @tullio bb_samples[re, step, chain] := \n         data_size * bb_weights[datum, re] * log_likelihood[datum, step, chain]\n     psis_object = psis(bb_samples, args...; kwargs...)\n     psis_weights = psis_object.weights\n"
                },
                {
                    "date": 1627497612889,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -56,9 +56,9 @@\n     # TODO: Add a way of using score functions other than ELPD\n     bb_weights = rand(rng, Dirichlet(ones(data_size)), resamples)\n     @tullio bb_samples[re, step, chain] := \n         data_size * bb_weights[datum, re] * log_likelihood[datum, step, chain]\n-    psis_object = psis(bb_samples, args...; kwargs...)\n+    psis_object = psis(1 .- bb_samples, args...; kwargs...)\n     psis_weights = psis_object.weights\n \n     @tullio re_naive[re] := log <| # calculate the naive estimate in many resamples\n         psis_weights[re, step, chain] * exp(bb_samples[re, step, chain])\n"
                },
                {
                    "date": 1627497697558,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -95,9 +95,10 @@\n \n     return BayesCV(\n         estimates,\n         resample_calcs,\n-        psis_object\n+        psis_object,\n+        data_size\n     )\n \n end\n \n"
                },
                {
                    "date": 1627498422778,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -56,9 +56,9 @@\n     # TODO: Add a way of using score functions other than ELPD\n     bb_weights = rand(rng, Dirichlet(ones(data_size)), resamples)\n     @tullio bb_samples[re, step, chain] := \n         data_size * bb_weights[datum, re] * log_likelihood[datum, step, chain]\n-    psis_object = psis(1 .- bb_samples, args...; kwargs...)\n+    psis_object = psis(bb_samples, args...; kwargs...)\n     psis_weights = psis_object.weights\n \n     @tullio re_naive[re] := log <| # calculate the naive estimate in many resamples\n         psis_weights[re, step, chain] * exp(bb_samples[re, step, chain])\n"
                },
                {
                    "date": 1627498758313,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -69,9 +69,9 @@\n \n     bb_ests = (2 * sample_est) .- re_naive\n     @tullio mcse[re] := sqrt <|\n         (psis_weights[re, step, chain] * (bb_samples[re, step, chain] - re_naive[re]))^2\n-    bootstrap_se = std(re_naive) / resamples\n+    bootstrap_se = std(re_naive) / sqrt(resamples)\n \n     # Posterior for the *average score*, not the mean of the posterior distribution:\n     resample_calcs = KeyedArray(\n         hcat(\n"
                },
                {
                    "date": 1627511164926,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -55,9 +55,9 @@\n \n     # TODO: Add a way of using score functions other than ELPD\n     bb_weights = rand(rng, Dirichlet(ones(data_size)), resamples)\n     @tullio bb_samples[re, step, chain] := \n-        data_size * bb_weights[datum, re] * log_likelihood[datum, step, chain]\n+        (data_size * bb_weights[datum, re] .- 1) * log_likelihood[datum, step, chain]\n     psis_object = psis(bb_samples, args...; kwargs...)\n     psis_weights = psis_object.weights\n \n     @tullio re_naive[re] := log <| # calculate the naive estimate in many resamples\n"
                },
                {
                    "date": 1627511191312,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -55,9 +55,9 @@\n \n     # TODO: Add a way of using score functions other than ELPD\n     bb_weights = rand(rng, Dirichlet(ones(data_size)), resamples)\n     @tullio bb_samples[re, step, chain] := \n-        (data_size * bb_weights[datum, re] .- 1) * log_likelihood[datum, step, chain]\n+        (data_size * bb_weights[datum, re] - 1) * log_likelihood[datum, step, chain]\n     psis_object = psis(bb_samples, args...; kwargs...)\n     psis_weights = psis_object.weights\n \n     @tullio re_naive[re] := log <| # calculate the naive estimate in many resamples\n"
                },
                {
                    "date": 1627511921038,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -55,14 +55,14 @@\n \n     # TODO: Add a way of using score functions other than ELPD\n     bb_weights = rand(rng, Dirichlet(ones(data_size)), resamples)\n     @tullio bb_samples[re, step, chain] := \n-        (data_size * bb_weights[datum, re] - 1) * log_likelihood[datum, step, chain]\n+        $data_size * bb_weights[datum, re] * log_likelihood[datum, step, chain]\n     psis_object = psis(bb_samples, args...; kwargs...)\n     psis_weights = psis_object.weights\n \n     @tullio re_naive[re] := log <| # calculate the naive estimate in many resamples\n-        psis_weights[re, step, chain] * exp(bb_samples[re, step, chain])\n+        psis_weights[re, step, chain] * exp(bb_samples[re, step, chain] - log_count)\n     @tullio sample_est := exp(log_likelihood[datum, step, chain] - log_count)\n     display(re_naive)\n     sample_est = log(sample_est)\n     display(sample_est)\n@@ -129,21 +129,21 @@\n     )\n \n     # calculate the sample expectation for the total score\n     to_sum = pointwise([:loo_est, :naive_est, :overfit])\n-    @tullio totals[crit] := to_sum[re, crit] / resamples\n-    totals = reshape(totals, 3)\n-    table(:, :total) .= totals\n+    @tullio averages[crit] := to_sum[re, crit] / resamples\n+    averages = reshape(averages, 3)\n+    table(:, :mean) .= averages\n \n     # calculate the sample expectation for the average score\n-    table(:, :mean) .= (averages = table(:, :total) / data_size)\n+    table(:, :total) .= table(:, :mean) * data_size\n \n     # calculate the sample expectation for the standard error in the totals\n-    se_mean = std(to_sum; mean=averages', dims=1) / sqrt(data_size)\n+    se_mean = std(to_sum; mean=averages', dims=1) * sqrt(data_size)\n     se_mean = reshape(se_mean, 3)\n     table(:, :se_mean) .= se_mean\n \n     # calculate the sample expectation for the standard error in averages\n-    table(:, :se_total) .= se_mean * data_size\n+    table(:, :se_total) .= se_mean / data_size\n \n     return table\n end\n"
                },
                {
                    "date": 1627512029625,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -48,8 +48,9 @@\n ) where {F<:AbstractFloat, T<:AbstractArray{F, 3}}\n \n     dims = size(log_likelihood)\n     data_size = dims[1]\n+    log_sample_size = log(data_size)\n     mcmc_count = dims[2] * dims[3]  # total number of samples from posterior\n     log_count = log(mcmc_count)\n \n \n@@ -60,10 +61,10 @@\n     psis_object = psis(bb_samples, args...; kwargs...)\n     psis_weights = psis_object.weights\n \n     @tullio re_naive[re] := log <| # calculate the naive estimate in many resamples\n-        psis_weights[re, step, chain] * exp(bb_samples[re, step, chain] - log_count)\n-    @tullio sample_est := exp(log_likelihood[datum, step, chain] - log_count)\n+        psis_weights[re, step, chain] * exp(bb_samples[re, step, chain] - log_sample_size)\n+    @tullio sample_est := exp(log_likelihood[datum, step, chain] - (log_count + log_sample_size))\n     display(re_naive)\n     sample_est = log(sample_est)\n     display(sample_est)\n \n"
                },
                {
                    "date": 1627512054151,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -48,9 +48,9 @@\n ) where {F<:AbstractFloat, T<:AbstractArray{F, 3}}\n \n     dims = size(log_likelihood)\n     data_size = dims[1]\n-    log_sample_size = log(data_size)\n+    log_data = log(data_size)\n     mcmc_count = dims[2] * dims[3]  # total number of samples from posterior\n     log_count = log(mcmc_count)\n \n \n@@ -61,10 +61,10 @@\n     psis_object = psis(bb_samples, args...; kwargs...)\n     psis_weights = psis_object.weights\n \n     @tullio re_naive[re] := log <| # calculate the naive estimate in many resamples\n-        psis_weights[re, step, chain] * exp(bb_samples[re, step, chain] - log_sample_size)\n-    @tullio sample_est := exp(log_likelihood[datum, step, chain] - (log_count + log_sample_size))\n+        psis_weights[re, step, chain] * exp(bb_samples[re, step, chain] - log_data)\n+    @tullio sample_est := exp(log_likelihood[datum, step, chain] - (log_count + log_data))\n     display(re_naive)\n     sample_est = log(sample_est)\n     display(sample_est)\n \n"
                },
                {
                    "date": 1627512110264,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -61,10 +61,10 @@\n     psis_object = psis(bb_samples, args...; kwargs...)\n     psis_weights = psis_object.weights\n \n     @tullio re_naive[re] := log <| # calculate the naive estimate in many resamples\n-        psis_weights[re, step, chain] * exp(bb_samples[re, step, chain] - log_data)\n-    @tullio sample_est := exp(log_likelihood[datum, step, chain] - (log_count + log_data))\n+        psis_weights[re, step, chain] * exp(bb_samples[re, step, chain])\n+    @tullio sample_est := exp(log_likelihood[datum, step, chain] - log_count)\n     display(re_naive)\n     sample_est = log(sample_est)\n     display(sample_est)\n \n"
                },
                {
                    "date": 1627608924433,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -64,8 +64,9 @@\n     @tullio re_naive[re] := log <| # calculate the naive estimate in many resamples\n         psis_weights[re, step, chain] * exp(bb_samples[re, step, chain])\n     @tullio sample_est := exp(log_likelihood[datum, step, chain] - log_count)\n     display(re_naive)\n+    \n     sample_est = log(sample_est)\n     display(sample_est)\n \n     bb_ests = (2 * sample_est) .- re_naive\n"
                },
                {
                    "date": 1627608984341,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -62,9 +62,9 @@\n     psis_weights = psis_object.weights\n \n     @tullio re_naive[re] := log <| # calculate the naive estimate in many resamples\n         psis_weights[re, step, chain] * exp(bb_samples[re, step, chain])\n-    @tullio sample_est := exp(log_likelihood[datum, step, chain] - log_count)\n+    @tullio sample_est := exp(log_likelihood[i, j, k] - log_count) |> log\n     display(re_naive)\n     \n     sample_est = log(sample_est)\n     display(sample_est)\n"
                },
                {
                    "date": 1627609015179,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -62,9 +62,9 @@\n     psis_weights = psis_object.weights\n \n     @tullio re_naive[re] := log <| # calculate the naive estimate in many resamples\n         psis_weights[re, step, chain] * exp(bb_samples[re, step, chain])\n-    @tullio sample_est := exp(log_likelihood[i, j, k] - log_count) |> log\n+    @tullio sample_est := exp(log_likelihood[i, j, k] - log_count)\n     display(re_naive)\n     \n     sample_est = log(sample_est)\n     display(sample_est)\n"
                },
                {
                    "date": 1627609080798,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -62,9 +62,9 @@\n     psis_weights = psis_object.weights\n \n     @tullio re_naive[re] := log <| # calculate the naive estimate in many resamples\n         psis_weights[re, step, chain] * exp(bb_samples[re, step, chain])\n-    @tullio sample_est := exp(log_likelihood[i, j, k] - log_count)\n+    @tullio sample_est := exp(log_likelihood[i, j, k] - log_count - log_data)\n     display(re_naive)\n     \n     sample_est = log(sample_est)\n     display(sample_est)\n"
                },
                {
                    "date": 1627609096785,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -62,9 +62,9 @@\n     psis_weights = psis_object.weights\n \n     @tullio re_naive[re] := log <| # calculate the naive estimate in many resamples\n         psis_weights[re, step, chain] * exp(bb_samples[re, step, chain])\n-    @tullio sample_est := exp(log_likelihood[i, j, k] - log_count - log_data)\n+    @tullio sample_est := exp(log_likelihood[i, j, k] - 2 * log_count - log_data)\n     display(re_naive)\n     \n     sample_est = log(sample_est)\n     display(sample_est)\n"
                },
                {
                    "date": 1627609115980,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -62,9 +62,9 @@\n     psis_weights = psis_object.weights\n \n     @tullio re_naive[re] := log <| # calculate the naive estimate in many resamples\n         psis_weights[re, step, chain] * exp(bb_samples[re, step, chain])\n-    @tullio sample_est := exp(log_likelihood[i, j, k] - 2 * log_count - log_data)\n+    @tullio sample_est[i] := exp(log_likelihood[i, j, k] - log_count)\n     display(re_naive)\n     \n     sample_est = log(sample_est)\n     display(sample_est)\n"
                },
                {
                    "date": 1627609194481,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -62,15 +62,16 @@\n     psis_weights = psis_object.weights\n \n     @tullio re_naive[re] := log <| # calculate the naive estimate in many resamples\n         psis_weights[re, step, chain] * exp(bb_samples[re, step, chain])\n-    @tullio sample_est[i] := exp(log_likelihood[i, j, k] - log_count)\n+    @tullio sample_est[i] := exp(log_likelihood[i, j, k] - log_count) |> log\n+    @tullio naive_est := naive_est\n     display(re_naive)\n     \n-    sample_est = log(sample_est)\n-    display(sample_est)\n+    naive_est = log(naive_est)\n+    display(naive_est)\n \n-    bb_ests = (2 * sample_est) .- re_naive\n+    bb_ests = (2 * naive_est) .- re_naive\n     @tullio mcse[re] := sqrt <|\n         (psis_weights[re, step, chain] * (bb_samples[re, step, chain] - re_naive[re]))^2\n     bootstrap_se = std(re_naive) / sqrt(resamples)\n \n"
                },
                {
                    "date": 1627609211585,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -63,9 +63,9 @@\n \n     @tullio re_naive[re] := log <| # calculate the naive estimate in many resamples\n         psis_weights[re, step, chain] * exp(bb_samples[re, step, chain])\n     @tullio sample_est[i] := exp(log_likelihood[i, j, k] - log_count) |> log\n-    @tullio naive_est := naive_est\n+    @tullio naive_est := sample_est\n     display(re_naive)\n     \n     naive_est = log(naive_est)\n     display(naive_est)\n"
                },
                {
                    "date": 1627609218670,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -62,9 +62,9 @@\n     psis_weights = psis_object.weights\n \n     @tullio re_naive[re] := log <| # calculate the naive estimate in many resamples\n         psis_weights[re, step, chain] * exp(bb_samples[re, step, chain])\n-    @tullio sample_est[i] := exp(log_likelihood[i, j, k] - log_count) |> log\n+    @tullio sample_est[i] := exp(log_likelihood[i, j, k] - log_count - log_data) |> log\n     @tullio naive_est := sample_est\n     display(re_naive)\n     \n     naive_est = log(naive_est)\n"
                },
                {
                    "date": 1627609263263,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -62,10 +62,10 @@\n     psis_weights = psis_object.weights\n \n     @tullio re_naive[re] := log <| # calculate the naive estimate in many resamples\n         psis_weights[re, step, chain] * exp(bb_samples[re, step, chain])\n-    @tullio sample_est[i] := exp(log_likelihood[i, j, k] - log_count - log_data) |> log\n-    @tullio naive_est := sample_est\n+    @tullio sample_est[i] := exp(log_likelihood[i, j, k] - log_count) |> log\n+    @tullio naive_est := sample_est |> _ / data_size\n     display(re_naive)\n     \n     naive_est = log(naive_est)\n     display(naive_est)\n"
                },
                {
                    "date": 1627609279497,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -62,10 +62,10 @@\n     psis_weights = psis_object.weights\n \n     @tullio re_naive[re] := log <| # calculate the naive estimate in many resamples\n         psis_weights[re, step, chain] * exp(bb_samples[re, step, chain])\n-    @tullio sample_est[i] := exp(log_likelihood[i, j, k] - log_count) |> log\n-    @tullio naive_est := sample_est |> _ / data_size\n+    @tullio sample_est[i] := exp(log_likelihood[i, j, k] - log_count - log_data) |> log\n+    @tullio naive_est := sample_est\n     display(re_naive)\n     \n     naive_est = log(naive_est)\n     display(naive_est)\n"
                },
                {
                    "date": 1627609310711,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -63,9 +63,9 @@\n \n     @tullio re_naive[re] := log <| # calculate the naive estimate in many resamples\n         psis_weights[re, step, chain] * exp(bb_samples[re, step, chain])\n     @tullio sample_est[i] := exp(log_likelihood[i, j, k] - log_count - log_data) |> log\n-    @tullio naive_est := sample_est\n+    @tullio naive_est := sample_est[i]\n     display(re_naive)\n     \n     naive_est = log(naive_est)\n     display(naive_est)\n"
                },
                {
                    "date": 1627609341715,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -65,10 +65,8 @@\n         psis_weights[re, step, chain] * exp(bb_samples[re, step, chain])\n     @tullio sample_est[i] := exp(log_likelihood[i, j, k] - log_count - log_data) |> log\n     @tullio naive_est := sample_est[i]\n     display(re_naive)\n-    \n-    naive_est = log(naive_est)\n     display(naive_est)\n \n     bb_ests = (2 * naive_est) .- re_naive\n     @tullio mcse[re] := sqrt <|\n"
                },
                {
                    "date": 1627609365075,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -62,9 +62,9 @@\n     psis_weights = psis_object.weights\n \n     @tullio re_naive[re] := log <| # calculate the naive estimate in many resamples\n         psis_weights[re, step, chain] * exp(bb_samples[re, step, chain])\n-    @tullio sample_est[i] := exp(log_likelihood[i, j, k] - log_count - log_data) |> log\n+    @tullio sample_est[i] := exp(log_likelihood[i, j, k] - log_count) |> log\n     @tullio naive_est := sample_est[i]\n     display(re_naive)\n     display(naive_est)\n \n"
                },
                {
                    "date": 1627609415413,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -56,9 +56,9 @@\n \n     # TODO: Add a way of using score functions other than ELPD\n     bb_weights = rand(rng, Dirichlet(ones(data_size)), resamples)\n     @tullio bb_samples[re, step, chain] := \n-        $data_size * bb_weights[datum, re] * log_likelihood[datum, step, chain]\n+        $data_size * (bb_weights[datum, re] - 1) * log_likelihood[datum, step, chain]\n     psis_object = psis(bb_samples, args...; kwargs...)\n     psis_weights = psis_object.weights\n \n     @tullio re_naive[re] := log <| # calculate the naive estimate in many resamples\n"
                },
                {
                    "date": 1627609437272,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -56,9 +56,9 @@\n \n     # TODO: Add a way of using score functions other than ELPD\n     bb_weights = rand(rng, Dirichlet(ones(data_size)), resamples)\n     @tullio bb_samples[re, step, chain] := \n-        $data_size * (bb_weights[datum, re] - 1) * log_likelihood[datum, step, chain]\n+        ($data_size * bb_weights[datum, re] - 1) * log_likelihood[datum, step, chain]\n     psis_object = psis(bb_samples, args...; kwargs...)\n     psis_weights = psis_object.weights\n \n     @tullio re_naive[re] := log <| # calculate the naive estimate in many resamples\n"
                },
                {
                    "date": 1627609453867,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -56,9 +56,9 @@\n \n     # TODO: Add a way of using score functions other than ELPD\n     bb_weights = rand(rng, Dirichlet(ones(data_size)), resamples)\n     @tullio bb_samples[re, step, chain] := \n-        ($data_size * bb_weights[datum, re] - 1) * log_likelihood[datum, step, chain]\n+        $data_size * bb_weights[datum, re] * log_likelihood[datum, step, chain]\n     psis_object = psis(bb_samples, args...; kwargs...)\n     psis_weights = psis_object.weights\n \n     @tullio re_naive[re] := log <| # calculate the naive estimate in many resamples\n"
                },
                {
                    "date": 1627609502807,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -61,10 +61,10 @@\n     psis_object = psis(bb_samples, args...; kwargs...)\n     psis_weights = psis_object.weights\n \n     @tullio re_naive[re] := log <| # calculate the naive estimate in many resamples\n-        psis_weights[re, step, chain] * exp(bb_samples[re, step, chain])\n-    @tullio sample_est[i] := exp(log_likelihood[i, j, k] - log_count) |> log\n+        psis_weights[re, step, chain] * exp(bb_samples[re, step, chain] - log_data)\n+    @tullio sample_est[i] := exp(log_likelihood[i, j, k] - log_count - log_data) |> log\n     @tullio naive_est := sample_est[i]\n     display(re_naive)\n     display(naive_est)\n \n"
                },
                {
                    "date": 1627609520942,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -61,10 +61,10 @@\n     psis_object = psis(bb_samples, args...; kwargs...)\n     psis_weights = psis_object.weights\n \n     @tullio re_naive[re] := log <| # calculate the naive estimate in many resamples\n-        psis_weights[re, step, chain] * exp(bb_samples[re, step, chain] - log_data)\n-    @tullio sample_est[i] := exp(log_likelihood[i, j, k] - log_count - log_data) |> log\n+        psis_weights[re, step, chain] * exp(bb_samples[re, step, chain])\n+    @tullio sample_est[i] := exp(log_likelihood[i, j, k] - log_count) |> log\n     @tullio naive_est := sample_est[i]\n     display(re_naive)\n     display(naive_est)\n \n"
                },
                {
                    "date": 1627609536862,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -64,10 +64,8 @@\n     @tullio re_naive[re] := log <| # calculate the naive estimate in many resamples\n         psis_weights[re, step, chain] * exp(bb_samples[re, step, chain])\n     @tullio sample_est[i] := exp(log_likelihood[i, j, k] - log_count) |> log\n     @tullio naive_est := sample_est[i]\n-    display(re_naive)\n-    display(naive_est)\n \n     bb_ests = (2 * naive_est) .- re_naive\n     @tullio mcse[re] := sqrt <|\n         (psis_weights[re, step, chain] * (bb_samples[re, step, chain] - re_naive[re]))^2\n"
                },
                {
                    "date": 1627610996619,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -128,21 +128,21 @@\n     )\n \n     # calculate the sample expectation for the total score\n     to_sum = pointwise([:loo_est, :naive_est, :overfit])\n-    @tullio averages[crit] := to_sum[re, crit] / resamples\n+    @tullio averages[crit] := to_sum[re, crit] / resamples / data_size\n     averages = reshape(averages, 3)\n     table(:, :mean) .= averages\n \n     # calculate the sample expectation for the average score\n     table(:, :total) .= table(:, :mean) * data_size\n \n     # calculate the sample expectation for the standard error in the totals\n-    se_mean = std(to_sum; mean=averages', dims=1) * sqrt(data_size)\n+    se_mean = std(to_sum; mean=averages', dims=1) / sqrt(data_size)\n     se_mean = reshape(se_mean, 3)\n     table(:, :se_mean) .= se_mean\n \n     # calculate the sample expectation for the standard error in averages\n-    table(:, :se_total) .= se_mean / data_size\n+    table(:, :se_total) .= se_mean * data_size\n \n     return table\n end\n"
                },
                {
                    "date": 1627611416879,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -64,8 +64,9 @@\n     @tullio re_naive[re] := log <| # calculate the naive estimate in many resamples\n         psis_weights[re, step, chain] * exp(bb_samples[re, step, chain])\n     @tullio sample_est[i] := exp(log_likelihood[i, j, k] - log_count) |> log\n     @tullio naive_est := sample_est[i]\n+    display(naive_est)\n \n     bb_ests = (2 * naive_est) .- re_naive\n     @tullio mcse[re] := sqrt <|\n         (psis_weights[re, step, chain] * (bb_samples[re, step, chain] - re_naive[re]))^2\n"
                },
                {
                    "date": 1627611710954,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -64,9 +64,8 @@\n     @tullio re_naive[re] := log <| # calculate the naive estimate in many resamples\n         psis_weights[re, step, chain] * exp(bb_samples[re, step, chain])\n     @tullio sample_est[i] := exp(log_likelihood[i, j, k] - log_count) |> log\n     @tullio naive_est := sample_est[i]\n-    display(naive_est)\n \n     bb_ests = (2 * naive_est) .- re_naive\n     @tullio mcse[re] := sqrt <|\n         (psis_weights[re, step, chain] * (bb_samples[re, step, chain] - re_naive[re]))^2\n"
                },
                {
                    "date": 1627612133229,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -57,8 +57,10 @@\n     # TODO: Add a way of using score functions other than ELPD\n     bb_weights = rand(rng, Dirichlet(ones(data_size)), resamples)\n     @tullio bb_samples[re, step, chain] := \n         $data_size * bb_weights[datum, re] * log_likelihood[datum, step, chain]\n+    @tullio log_is_ratios[re, step, chain] := \n+        bb_samples[re, step, chain] - log_likelihood[datum, step, chain]\n     psis_object = psis(bb_samples, args...; kwargs...)\n     psis_weights = psis_object.weights\n \n     @tullio re_naive[re] := log <| # calculate the naive estimate in many resamples\n@@ -136,9 +138,9 @@\n     # calculate the sample expectation for the average score\n     table(:, :total) .= table(:, :mean) * data_size\n \n     # calculate the sample expectation for the standard error in the totals\n-    se_mean = std(to_sum; mean=averages', dims=1) / sqrt(data_size)\n+    se_mean = std(to_sum; mean=averages, dims=2) / sqrt(data_size)\n     se_mean = reshape(se_mean, 3)\n     table(:, :se_mean) .= se_mean\n \n     # calculate the sample expectation for the standard error in averages\n"
                },
                {
                    "date": 1627612272232,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -48,9 +48,8 @@\n ) where {F<:AbstractFloat, T<:AbstractArray{F, 3}}\n \n     dims = size(log_likelihood)\n     data_size = dims[1]\n-    log_data = log(data_size)\n     mcmc_count = dims[2] * dims[3]  # total number of samples from posterior\n     log_count = log(mcmc_count)\n \n \n"
                },
                {
                    "date": 1627612313387,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -58,9 +58,9 @@\n     @tullio bb_samples[re, step, chain] := \n         $data_size * bb_weights[datum, re] * log_likelihood[datum, step, chain]\n     @tullio log_is_ratios[re, step, chain] := \n         bb_samples[re, step, chain] - log_likelihood[datum, step, chain]\n-    psis_object = psis(bb_samples, args...; kwargs...)\n+    psis_object = psis(log_is_ratios, args...; kwargs...)\n     psis_weights = psis_object.weights\n \n     @tullio re_naive[re] := log <| # calculate the naive estimate in many resamples\n         psis_weights[re, step, chain] * exp(bb_samples[re, step, chain])\n"
                },
                {
                    "date": 1627612346154,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -58,8 +58,9 @@\n     @tullio bb_samples[re, step, chain] := \n         $data_size * bb_weights[datum, re] * log_likelihood[datum, step, chain]\n     @tullio log_is_ratios[re, step, chain] := \n         bb_samples[re, step, chain] - log_likelihood[datum, step, chain]\n+    display(log_is_ratios)\n     psis_object = psis(log_is_ratios, args...; kwargs...)\n     psis_weights = psis_object.weights\n \n     @tullio re_naive[re] := log <| # calculate the naive estimate in many resamples\n"
                },
                {
                    "date": 1627612609689,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,150 @@\n+using AxisKeys\n+using InteractiveUtils\n+using LoopVectorization\n+using Random\n+using Statistics\n+using Tullio\n+\n+export bayes_cv\n+\n+\"\"\"\n+    function bayes_cv(\n+        log_likelihood::Array{Float} [, args...];\n+        source::String=\"mcmc\" [, chain_index::Vector{Int}, kwargs...]\n+    ) -> PsisBB\n+\n+Use the Bayesian bootstrap (Bayes cross-validation) and PSIS to calculate an approximate\n+posterior for the out-of-sample score.\n+\n+\n+# Arguments\n+\n+  - `log_likelihood::Array`: An array or matrix of log-likelihood values indexed as\n+    `[data, step, chain]`. The chain argument can be left off if `chain_index` is provided\n+    or if all posterior samples were drawn from a single chain.\n+  - `args...`: Positional arguments to be passed to [`psis`](@ref).\n+  - `chain_index::Vector`: An (optional) vector of integers specifying which chain each\n+    step belongs to. For instance, `chain_index[3]` should return `2` if\n+    `log_likelihood[:, 3]` belongs to the second chain.\n+  - `kwargs...`: Keyword arguments to be passed to [`psis`](@ref).\n+\n+\n+# Extended help\n+The Bayesian bootstrap works similarly to other cross-validation methods: First, we remove\n+some piece of information from the model. Then, we test how well the model can reproduce \n+that information. With leave-k-out cross validation, the information we leave out is the\n+value for one or more data points. With the Bayesian bootstrap, the information being left\n+out is the true probability of each observation.\n+\n+\n+See also: [`BayesCV`](@ref), [`psis`](@ref), [`loo`](@ref), [`PsisLoo`](@ref).\n+\"\"\"\n+function bayes_cv(\n+    log_likelihood::T, \n+    args...;\n+    resamples::Integer=2^10, \n+    rng=MersenneTwister(1776),\n+    kwargs...\n+) where {F<:AbstractFloat, T<:AbstractArray{F, 3}}\n+\n+    dims = size(log_likelihood)\n+    data_size = dims[1]\n+    mcmc_count = dims[2] * dims[3]  # total number of samples from posterior\n+    log_count = log(mcmc_count)\n+\n+\n+    # TODO: Add a way of using score functions other than ELPD\n+    bb_weights = rand(rng, Dirichlet(ones(data_size)), resamples)\n+    @tullio bb_samples[re, step, chain] := \n+        $data_size * bb_weights[datum, re] * log_likelihood[datum, step, chain]\n+    @tullio log_is_ratios[re, step, chain] := \n+        bb_samples[re, step, chain]\n+    display(log_is_ratios)\n+    psis_object = psis(log_is_ratios, args...; kwargs...)\n+    psis_weights = psis_object.weights\n+\n+    @tullio re_naive[re] := log <| # calculate the naive estimate in many resamples\n+        psis_weights[re, step, chain] * exp(bb_samples[re, step, chain])\n+    @tullio sample_est[i] := exp(log_likelihood[i, j, k] - log_count) |> log\n+    @tullio naive_est := sample_est[i]\n+\n+    bb_ests = (2 * naive_est) .- re_naive\n+    @tullio mcse[re] := sqrt <|\n+        (psis_weights[re, step, chain] * (bb_samples[re, step, chain] - re_naive[re]))^2\n+    bootstrap_se = std(re_naive) / sqrt(resamples)\n+\n+    # Posterior for the *average score*, not the mean of the posterior distribution:\n+    resample_calcs = KeyedArray(\n+        hcat(\n+            bb_ests,\n+            re_naive,\n+            re_naive - bb_ests,\n+            mcse,\n+            psis_object.pareto_k\n+        );\n+        data=Base.OneTo(resamples),\n+        statistic=[\n+            :loo_est,\n+            :naive_est,\n+            :overfit,\n+            :mcse,\n+            :pareto_k\n+        ],\n+    )\n+\n+    estimates = _generate_bayes_table(log_likelihood, resample_calcs, resamples, data_size)\n+\n+    return BayesCV(\n+        estimates,\n+        resample_calcs,\n+        psis_object,\n+        data_size\n+    )\n+\n+end\n+\n+\n+function bayes_cv(\n+    log_likelihood::T,\n+    args...;\n+    chain_index::AbstractVector=ones(size(log_likelihood, 1)),\n+    kwargs...,\n+) where {F<:AbstractFloat, T<:AbstractMatrix{F}}\n+    new_log_ratios = _convert_to_array(log_likelihood, chain_index)\n+    return psis_loo(new_log_ratios, args...; kwargs...)\n+end\n+\n+\n+function _generate_bayes_table(\n+    log_likelihood::AbstractArray, \n+    pointwise::AbstractArray, \n+    resamples::Integer,\n+    data_size::Integer\n+)\n+\n+    # create table with the right labels\n+    table = KeyedArray(\n+        similar(log_likelihood, 3, 4);\n+        criterion=[:loo_est, :naive_est, :overfit],\n+        statistic=[:total, :se_total, :mean, :se_mean],\n+    )\n+\n+    # calculate the sample expectation for the total score\n+    to_sum = pointwise([:loo_est, :naive_est, :overfit])\n+    @tullio averages[crit] := to_sum[re, crit] / resamples / data_size\n+    averages = reshape(averages, 3)\n+    table(:, :mean) .= averages\n+\n+    # calculate the sample expectation for the average score\n+    table(:, :total) .= table(:, :mean) * data_size\n+\n+    # calculate the sample expectation for the standard error in the totals\n+    se_mean = std(to_sum; mean=averages, dims=2) / sqrt(data_size)\n+    se_mean = reshape(se_mean, 3)\n+    table(:, :se_mean) .= se_mean\n+\n+    # calculate the sample expectation for the standard error in averages\n+    table(:, :se_total) .= se_mean * data_size\n+\n+    return table\n+end\n"
                },
                {
                    "date": 1627612824260,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -53,13 +53,12 @@\n     log_count = log(mcmc_count)\n \n \n     # TODO: Add a way of using score functions other than ELPD\n-    bb_weights = rand(rng, Dirichlet(ones(data_size)), resamples)\n+    bb_weights = data_size * rand(rng, Dirichlet(ones(data_size)), resamples)\n     @tullio bb_samples[re, step, chain] := \n-        $data_size * bb_weights[datum, re] * log_likelihood[datum, step, chain]\n+        bb_weights[datum, re] * log_likelihood[datum, step, chain]\n     @tullio log_is_ratios[re, step, chain] := \n-        bb_samples[re, step, chain]\n     display(log_is_ratios)\n     psis_object = psis(log_is_ratios, args...; kwargs...)\n     psis_weights = psis_object.weights\n \n@@ -147,154 +146,4 @@\n     table(:, :se_total) .= se_mean * data_size\n \n     return table\n end\n-using AxisKeys\n-using InteractiveUtils\n-using LoopVectorization\n-using Random\n-using Statistics\n-using Tullio\n-\n-export bayes_cv\n-\n-\"\"\"\n-    function bayes_cv(\n-        log_likelihood::Array{Float} [, args...];\n-        source::String=\"mcmc\" [, chain_index::Vector{Int}, kwargs...]\n-    ) -> PsisBB\n-\n-Use the Bayesian bootstrap (Bayes cross-validation) and PSIS to calculate an approximate\n-posterior for the out-of-sample score.\n-\n-\n-# Arguments\n-\n-  - `log_likelihood::Array`: An array or matrix of log-likelihood values indexed as\n-    `[data, step, chain]`. The chain argument can be left off if `chain_index` is provided\n-    or if all posterior samples were drawn from a single chain.\n-  - `args...`: Positional arguments to be passed to [`psis`](@ref).\n-  - `chain_index::Vector`: An (optional) vector of integers specifying which chain each\n-    step belongs to. For instance, `chain_index[3]` should return `2` if\n-    `log_likelihood[:, 3]` belongs to the second chain.\n-  - `kwargs...`: Keyword arguments to be passed to [`psis`](@ref).\n-\n-\n-# Extended help\n-The Bayesian bootstrap works similarly to other cross-validation methods: First, we remove\n-some piece of information from the model. Then, we test how well the model can reproduce \n-that information. With leave-k-out cross validation, the information we leave out is the\n-value for one or more data points. With the Bayesian bootstrap, the information being left\n-out is the true probability of each observation.\n-\n-\n-See also: [`BayesCV`](@ref), [`psis`](@ref), [`loo`](@ref), [`PsisLoo`](@ref).\n-\"\"\"\n-function bayes_cv(\n-    log_likelihood::T, \n-    args...;\n-    resamples::Integer=2^10, \n-    rng=MersenneTwister(1776),\n-    kwargs...\n-) where {F<:AbstractFloat, T<:AbstractArray{F, 3}}\n-\n-    dims = size(log_likelihood)\n-    data_size = dims[1]\n-    mcmc_count = dims[2] * dims[3]  # total number of samples from posterior\n-    log_count = log(mcmc_count)\n-\n-\n-    # TODO: Add a way of using score functions other than ELPD\n-    bb_weights = rand(rng, Dirichlet(ones(data_size)), resamples)\n-    @tullio bb_samples[re, step, chain] := \n-        $data_size * bb_weights[datum, re] * log_likelihood[datum, step, chain]\n-    @tullio log_is_ratios[re, step, chain] := \n-        bb_samples[re, step, chain] - log_likelihood[datum, step, chain]\n-    display(log_is_ratios)\n-    psis_object = psis(log_is_ratios, args...; kwargs...)\n-    psis_weights = psis_object.weights\n-\n-    @tullio re_naive[re] := log <| # calculate the naive estimate in many resamples\n-        psis_weights[re, step, chain] * exp(bb_samples[re, step, chain])\n-    @tullio sample_est[i] := exp(log_likelihood[i, j, k] - log_count) |> log\n-    @tullio naive_est := sample_est[i]\n-\n-    bb_ests = (2 * naive_est) .- re_naive\n-    @tullio mcse[re] := sqrt <|\n-        (psis_weights[re, step, chain] * (bb_samples[re, step, chain] - re_naive[re]))^2\n-    bootstrap_se = std(re_naive) / sqrt(resamples)\n-\n-    # Posterior for the *average score*, not the mean of the posterior distribution:\n-    resample_calcs = KeyedArray(\n-        hcat(\n-            bb_ests,\n-            re_naive,\n-            re_naive - bb_ests,\n-            mcse,\n-            psis_object.pareto_k\n-        );\n-        data=Base.OneTo(resamples),\n-        statistic=[\n-            :loo_est,\n-            :naive_est,\n-            :overfit,\n-            :mcse,\n-            :pareto_k\n-        ],\n-    )\n-\n-    estimates = _generate_bayes_table(log_likelihood, resample_calcs, resamples, data_size)\n-\n-    return BayesCV(\n-        estimates,\n-        resample_calcs,\n-        psis_object,\n-        data_size\n-    )\n-\n-end\n-\n-\n-function bayes_cv(\n-    log_likelihood::T,\n-    args...;\n-    chain_index::AbstractVector=ones(size(log_likelihood, 1)),\n-    kwargs...,\n-) where {F<:AbstractFloat, T<:AbstractMatrix{F}}\n-    new_log_ratios = _convert_to_array(log_likelihood, chain_index)\n-    return psis_loo(new_log_ratios, args...; kwargs...)\n-end\n-\n-\n-function _generate_bayes_table(\n-    log_likelihood::AbstractArray, \n-    pointwise::AbstractArray, \n-    resamples::Integer,\n-    data_size::Integer\n-)\n-\n-    # create table with the right labels\n-    table = KeyedArray(\n-        similar(log_likelihood, 3, 4);\n-        criterion=[:loo_est, :naive_est, :overfit],\n-        statistic=[:total, :se_total, :mean, :se_mean],\n-    )\n-\n-    # calculate the sample expectation for the total score\n-    to_sum = pointwise([:loo_est, :naive_est, :overfit])\n-    @tullio averages[crit] := to_sum[re, crit] / resamples / data_size\n-    averages = reshape(averages, 3)\n-    table(:, :mean) .= averages\n-\n-    # calculate the sample expectation for the average score\n-    table(:, :total) .= table(:, :mean) * data_size\n-\n-    # calculate the sample expectation for the standard error in the totals\n-    se_mean = std(to_sum; mean=averages, dims=2) / sqrt(data_size)\n-    se_mean = reshape(se_mean, 3)\n-    table(:, :se_mean) .= se_mean\n-\n-    # calculate the sample expectation for the standard error in averages\n-    table(:, :se_total) .= se_mean * data_size\n-\n-    return table\n-end\n"
                },
                {
                    "date": 1627612910486,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -57,8 +57,9 @@\n     bb_weights = data_size * rand(rng, Dirichlet(ones(data_size)), resamples)\n     @tullio bb_samples[re, step, chain] := \n         bb_weights[datum, re] * log_likelihood[datum, step, chain]\n     @tullio log_is_ratios[re, step, chain] := \n+        (bb_weights[datum, re] - 1) * log_likelihood[datum, step, chain]\n     display(log_is_ratios)\n     psis_object = psis(log_is_ratios, args...; kwargs...)\n     psis_weights = psis_object.weights\n \n"
                },
                {
                    "date": 1627612945069,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -138,9 +138,9 @@\n     # calculate the sample expectation for the average score\n     table(:, :total) .= table(:, :mean) * data_size\n \n     # calculate the sample expectation for the standard error in the totals\n-    se_mean = std(to_sum; mean=averages, dims=2) / sqrt(data_size)\n+    se_mean = std(to_sum; mean=averages, dims=1) / sqrt(data_size)\n     se_mean = reshape(se_mean, 3)\n     table(:, :se_mean) .= se_mean\n \n     # calculate the sample expectation for the standard error in averages\n"
                },
                {
                    "date": 1627612961391,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -138,9 +138,9 @@\n     # calculate the sample expectation for the average score\n     table(:, :total) .= table(:, :mean) * data_size\n \n     # calculate the sample expectation for the standard error in the totals\n-    se_mean = std(to_sum; mean=averages, dims=1) / sqrt(data_size)\n+    se_mean = std(to_sum; dims=1) / sqrt(data_size)\n     se_mean = reshape(se_mean, 3)\n     table(:, :se_mean) .= se_mean\n \n     # calculate the sample expectation for the standard error in averages\n"
                },
                {
                    "date": 1627618461028,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -57,9 +57,9 @@\n     bb_weights = data_size * rand(rng, Dirichlet(ones(data_size)), resamples)\n     @tullio bb_samples[re, step, chain] := \n         bb_weights[datum, re] * log_likelihood[datum, step, chain]\n     @tullio log_is_ratios[re, step, chain] := \n-        (bb_weights[datum, re] - 1) * log_likelihood[datum, step, chain]\n+        bb_samples[re, step, chain] - log_likelihood[datum, step, chain]\n     display(log_is_ratios)\n     psis_object = psis(log_is_ratios, args...; kwargs...)\n     psis_weights = psis_object.weights\n \n"
                },
                {
                    "date": 1627618489272,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -57,9 +57,9 @@\n     bb_weights = data_size * rand(rng, Dirichlet(ones(data_size)), resamples)\n     @tullio bb_samples[re, step, chain] := \n         bb_weights[datum, re] * log_likelihood[datum, step, chain]\n     @tullio log_is_ratios[re, step, chain] := \n-        bb_samples[re, step, chain] - log_likelihood[datum, step, chain]\n+        (bb_weights[datum, re] - 1) * log_likelihood[datum, step, chain]\n     display(log_is_ratios)\n     psis_object = psis(log_is_ratios, args...; kwargs...)\n     psis_weights = psis_object.weights\n \n"
                },
                {
                    "date": 1627618670195,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -42,9 +42,9 @@\n function bayes_cv(\n     log_likelihood::T, \n     args...;\n     resamples::Integer=2^10, \n-    rng=MersenneTwister(1776),\n+    rng=MersenneTwister(1865),\n     kwargs...\n ) where {F<:AbstractFloat, T<:AbstractArray{F, 3}}\n \n     dims = size(log_likelihood)\n@@ -58,9 +58,8 @@\n     @tullio bb_samples[re, step, chain] := \n         bb_weights[datum, re] * log_likelihood[datum, step, chain]\n     @tullio log_is_ratios[re, step, chain] := \n         (bb_weights[datum, re] - 1) * log_likelihood[datum, step, chain]\n-    display(log_is_ratios)\n     psis_object = psis(log_is_ratios, args...; kwargs...)\n     psis_weights = psis_object.weights\n \n     @tullio re_naive[re] := log <| # calculate the naive estimate in many resamples\n"
                },
                {
                    "date": 1627620400015,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -13,9 +13,9 @@\n         source::String=\"mcmc\" [, chain_index::Vector{Int}, kwargs...]\n     ) -> PsisBB\n \n Use the Bayesian bootstrap (Bayes cross-validation) and PSIS to calculate an approximate\n-posterior for the out-of-sample score.\n+posterior distribution for the out-of-sample score.\n \n \n # Arguments\n \n"
                }
            ],
            "date": 1627341840659,
            "name": "Commit-0",
            "content": "using AxisKeys\nusing MeasureTheory\nusing InteractiveUtils\nusing LoopVectorization\nusing Statistics\nusing Tullio\n\nexport bayes_val\n\n\"\"\"\n    function bayes_cv(\n        log_likelihood::Array{Float} [, args...];\n        source::String=\"mcmc\" [, chain_index::Vector{Int}, kwargs...]\n    ) -> PsisBB\n\nUse the Bayesian bootstrap (Bayes cross-validation) and PSIS to calculate an approximate\nposterior for the out-of-sample score.\n\n\n# Arguments\n\n  - `log_likelihood::Array`: An array or matrix of log-likelihood values indexed as\n    `[data, step, chain]`. The chain argument can be left off if `chain_index` is provided\n    or if all posterior samples were drawn from a single chain.\n  - `args...`: Positional arguments to be passed to [`psis`](@ref).\n  - `chain_index::Vector`: An (optional) vector of integers specifying which chain each\n    step belongs to. For instance, `chain_index[3]` should return `2` if\n    `log_likelihood[:, 3]` belongs to the second chain.\n  - `kwargs...`: Keyword arguments to be passed to [`psis`](@ref).\n\n\n# Extended help\nThe Bayesian bootstrap works similarly to other cross-validation methods: First, we remove\nsome piece of information from the model. Then, we test how well the model can reproduce \nthat information. With leave-k-out cross validation, the information we leave out is the\nvalue for one or more data points. With the Bayesian bootstrap, the information being left\nout is the true probability of each observation.\n\n\nSee also: [`BayesCV`](@ref), [`psis`](@ref), [`loo`](@ref), [`PsisLoo`](@ref).\n\"\"\"\nfunction bayes_cv(\n    log_likelihood::T, \n    args...;\n    resamples::Integer=2^10, \n    rng=MersenneTwister(1776),\n    kwargs...\n) where {F<:AbstractFloat, T<:AbstractArray{F, 3}}\n\n    dims = size(log_likelihood)\n    data_size = dims[1]\n    mcmc_count = dims[2] * dims[3]  # total number of samples from posterior\n    log_count = log(mcmc_count)\n\n\n    # TODO: Add a way of using score functions other than ELPD\n    bb_weights = data_size * rand(rng, Dirichlet(ones(data_size)), resamples)\n    bb_samples = similar(log_likelihood, (resamples, data_size))\n    psis_object = psis(bb_samples, args...; kwargs...)\n\n    # \"Pointwise\" used here to refer to \"per resample\"\n    @tullio pointwise_naive[i] := log <|\n        psis_object.weights[i, j, k] * exp(bb_samples[i, j, k])\n    @tullio sample_est := exp(log_likelihood[i, j, k] - log_count)\n    sample_est = log(sample_est)\n    \n    @tturbo bb_ests .= (2 * sample_est) .- pointwise_naive\n    @tullio pointwise_mcse[i] :=  # I'll take sqrt later in-place\n        (weights[i, j, k] * (log_likelihood[i, j, k] - pointwise_loo[i]))^2\n    # Apply law of total variance\n    bootstrap_se = var(naive_ests) / bb_samples\n    mcse = sqrt(mean(pointwise_mcse) + bootstrap_se)\n    @tturbo @. pointwise_mcse = sqrt(pointwise_mcse)\n        \n    # Posterior for the *average score*, not the mean of the posterior distribution:\n    posterior_avg = bb_ests / data_size\n    resample_calcs = KeyedArray(\n        hcat(\n            bb_ests,\n            pointwise_naive,\n            pointwise_overfit,\n            pointwise_mcse,\n            psis_object.pareto_k\n        );\n        data=1:length(pointwise_loo),\n        statistic=[\n            :loo_est,\n            :naive_est,\n            :overfit,\n            :mcse,\n            :pareto_k\n        ],\n    )\n\n    estimates = _generate_bayes_table(log_likelihood, resample_calcs, data_size)\n\n    return BayesCV(\n        estimates,\n        resample_calcs,\n        psis_object\n    )\n\nend\n\n\nfunction bayes_cv(\n    log_likelihood::T,\n    args...;\n    chain_index::AbstractVector=ones(size(log_likelihood, 1)),\n    kwargs...,\n) where {F <: AbstractFloat, T <: AbstractMatrix{F}}\n    new_log_ratios = _convert_to_array(log_likelihood, chain_index)\n    return psis_loo(new_log_ratios, args...; kwargs...)\nend\n\n\nfunction _generate_bayes_table(\n    log_likelihood::AbstractArray, \n    pointwise::AbstractArray, \n    data_size::Integer\n)\n\n    # create table with the right labels\n    table = KeyedArray(\n        similar(log_likelihood, 3, 4);\n        criterion=[:cv_est, :naive_est, :overfit],\n        statistic=[:ev_total, :se_total, :ev_mean, :se_mean, :sd_mean],\n    )\n    \n    # calculate the sample expectation for the total score\n    to_sum = pointwise([:loo_est, :naive_est])\n    @tullio total[crit] := to_sum[data, crit]\n    table(:, :total) .= reshape(total, 3)\n\n    # calculate the sample expectation for the average score\n    table(:, :mean) .= table(:, :total) ./ data_size\n\n    # calculate the sample expectation for the standard error in the totals\n    @_ table(:, :se_total) .= pointwise([:loo_est, :naive_est, :overfit]) |> \n        varm(_, table(:, :mean); dims=1) |>\n        sqrt.(data_size * _) |>\n        reshape(_, 3)\n\n    # calculate the sample expectation for the standard error in averages\n    table(:, :se_mean) .= table(:, :se_total) ./ data_size\n\n    return table\nend\n"
        }
    ]
}