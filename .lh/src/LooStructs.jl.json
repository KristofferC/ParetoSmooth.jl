{
    "sourceFile": "src/LooStructs.jl",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 50,
            "patches": [
                {
                    "date": 1626484301733,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                },
                {
                    "date": 1626487363855,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -21,9 +21,8 @@\n struct PsisLooMethod <: AbstractLooMethod end\n \n \n function Base.show(io::IO, ::MIME\"text/plain\", loo_object::PsisLoo)\n-    _throw_pareto_k_warnings(loo_object.pointwise(:pareto_k))\n     table = loo_object.estimates\n     return pretty_table(\n         table;\n         compact_printing=false,\n"
                },
                {
                    "date": 1626542969541,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -3,8 +3,21 @@\n using PrettyTables\n export PsisLoo, AbstractLoo, AbstractLooMethod, PsisLooMethod\n \n abstract type AbstractLoo end\n+\n+\"\"\"\n+    PsisLoo\n+\n+A struct containing the results of Pareto-smoothed importance sampling.\n+\n+# Fields\n+\n+  - `estimates::KeyedArray`: A `KeyedArray` with two columns (`:Estimate`, `:SE`) and three\n+  rows (`:total_score`, `:avg_score`, )\n+  - `pointwise::KeyedArray`:\n+\n+\"\"\"\n struct PsisLoo{\n     F <: AbstractFloat,\n     AF <: AbstractArray{F},\n     VF <: AbstractVector{F},\n"
                },
                {
                    "date": 1626543164441,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -7,15 +7,17 @@\n \n \"\"\"\n     PsisLoo\n \n-A struct containing the results of Pareto-smoothed importance sampling.\n+A struct containing the results of leave-one-out cross validation, as \n \n # Fields\n \n   - `estimates::KeyedArray`: A `KeyedArray` with two columns (`:Estimate`, `:SE`) and three\n   rows (`:total_score`, `:avg_score`, )\n-  - `pointwise::KeyedArray`:\n+  - `pointwise::KeyedArray`: An array of pointwise \n+  - `psis_object::Psis`: A `Psis` object containing the results of Pareto-smoothed \n+  importance sampling.\n \n \"\"\"\n struct PsisLoo{\n     F <: AbstractFloat,\n"
                },
                {
                    "date": 1626543302586,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -17,8 +17,10 @@\n   - `pointwise::KeyedArray`: An array of pointwise \n   - `psis_object::Psis`: A `Psis` object containing the results of Pareto-smoothed \n   importance sampling.\n \n+See also: [`psis_loo`]@ref, [`Psis`]@ref, \n+\n \"\"\"\n struct PsisLoo{\n     F <: AbstractFloat,\n     AF <: AbstractArray{F},\n"
                },
                {
                    "date": 1626543483009,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -12,14 +12,14 @@\n \n # Fields\n \n   - `estimates::KeyedArray`: A `KeyedArray` with two columns (`:Estimate`, `:SE`) and three\n-  rows (`:total_score`, `:avg_score`, )\n+  rows (`:total_score`, `:avg_score`, `:`).\n   - `pointwise::KeyedArray`: An array of pointwise \n   - `psis_object::Psis`: A `Psis` object containing the results of Pareto-smoothed \n   importance sampling.\n \n-See also: [`psis_loo`]@ref, [`Psis`]@ref, \n+See also: [`psis_loo`]@ref, [`Psis`]@ref\n \n \"\"\"\n struct PsisLoo{\n     F <: AbstractFloat,\n"
                },
                {
                    "date": 1626559179093,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -5,20 +5,56 @@\n \n abstract type AbstractLoo end\n \n \"\"\"\n-    PsisLoo\n+    PsisLoo{\n+        F <: AbstractFloat,\n+        AF <: AbstractArray{F},\n+        VF <: AbstractVector{F},\n+        I <: Integer,\n+        VI <: AbstractVector{I},\n+    } <: AbstractLoo\n \n-A struct containing the results of leave-one-out cross validation, as \n+A struct containing the results of leave-one-out cross validation using Pareto smoothed\n+importance sampling.\n \n # Fields\n \n   - `estimates::KeyedArray`: A `KeyedArray` with two columns (`:Estimate`, `:SE`) and three\n-  rows (`:total_score`, `:avg_score`, `:`).\n-  - `pointwise::KeyedArray`: An array of pointwise \n+    rows (`:total_score`, `:overfit`, `:avg_score`). This contains point estimates and\n+    standard errors for the total log score (the sum of all errors); the effective number of \n+    parameters (difference between in-sample and out-of-sample predictive accuracy); and the\n+    average log-score (Sometimes referred to as the ELPD). See the extended help for more\n+    details.\n+  - `pointwise::KeyedArray`: An array of pointwise values\n   - `psis_object::Psis`: A `Psis` object containing the results of Pareto-smoothed \n-  importance sampling.\n+    importance sampling.\n \n+\n+# Extended help\n+\n+The total score depends on the sample size, and summarizes the weight of evidence for or\n+against a model. Total scores are on an interval scale, meaning that only differences of\n+scores are meaningful. *It is not possible to interpret a total score by looking at it.*\n+The total score is not a relative goodness-of-fit statistic (for this, see the average\n+score).\n+\n+\n+The overfit is equal to the difference between the in-sample and out-of-sample predictive\n+accuracy. When using the log probability score, it is equal to the \"effective number of\n+parameters\" -- a model with an overfit of 2 is \"about as overfit\" as a model that has 2 free\n+parameters.\n+\n+\n+The average score is the total score, divided by the sample size. It estimates the expected\n+log score, i.e. the expectation of the log probability density of observing the next point.\n+The average score is a relative goodness-of-fit statistic which does not depend on sample\n+size. \n+\n+\n+Unlike with chi-square goodness of fit tests, models do not have to be nested for PSIS-LOO.\n+\n+\n See also: [`psis_loo`]@ref, [`Psis`]@ref\n \n \"\"\"\n struct PsisLoo{\n"
                },
                {
                    "date": 1626566363530,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -40,10 +40,10 @@\n \n \n The overfit is equal to the difference between the in-sample and out-of-sample predictive\n accuracy. When using the log probability score, it is equal to the \"effective number of\n-parameters\" -- a model with an overfit of 2 is \"about as overfit\" as a model that has 2 free\n-parameters.\n+parameters\" -- a model with an overfit of 2 has \"about as much overfit\" as a model with 2\n+free parameters and flat priors.\n \n \n The average score is the total score, divided by the sample size. It estimates the expected\n log score, i.e. the expectation of the log probability density of observing the next point.\n"
                },
                {
                    "date": 1626625302819,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -72,11 +72,22 @@\n abstract type AbstractLooMethod end\n \n struct PsisLooMethod <: AbstractLooMethod end\n \n+function _throw_pareto_k_warning(ξ)\n+    if any(ξ .≥ .7)\n+        @warn \"Some Pareto k values are very high (>0.7), indicating that PSIS has \" * \n+        \"failed to approximate the true distribution. Treat these estimates with caution.\"\n+    elseif any(ξ .≥ .5)\n+        @info \"Some Pareto k values are slightly high (>0.5); some pointwise estimates \" *\n+        \"may be slightly unreliable.\"\n+    end\n+end\n \n+\n function Base.show(io::IO, ::MIME\"text/plain\", loo_object::PsisLoo)\n     table = loo_object.estimates\n+    _throw_pareto_k_warning(loo_object.pointwise(:pareto_k))\n     return pretty_table(\n         table;\n         compact_printing=false,\n         header=table.estimate,\n"
                },
                {
                    "date": 1626625339167,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -75,12 +75,12 @@\n \n function _throw_pareto_k_warning(ξ)\n     if any(ξ .≥ .7)\n         @warn \"Some Pareto k values are very high (>0.7), indicating that PSIS has \" * \n-        \"failed to approximate the true distribution. Treat these estimates with caution.\"\n+        \"failed to approximate the true distribution.\"\n     elseif any(ξ .≥ .5)\n         @info \"Some Pareto k values are slightly high (>0.5); some pointwise estimates \" *\n-        \"may be slightly unreliable.\"\n+        \"may be slow to converge or have high variance.\"\n     end\n end\n \n \n"
                },
                {
                    "date": 1626663823479,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -89,9 +89,9 @@\n     _throw_pareto_k_warning(loo_object.pointwise(:pareto_k))\n     return pretty_table(\n         table;\n         compact_printing=false,\n-        header=table.estimate,\n+        header=table.statistic,\n         row_names=table.criterion,\n         formatters=ft_printf(\"%5.2f\"),\n         alignment=:r,\n     )\n"
                },
                {
                    "date": 1626977174718,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -50,9 +50,10 @@\n The average score is a relative goodness-of-fit statistic which does not depend on sample\n size. \n \n \n-Unlike with chi-square goodness of fit tests, models do not have to be nested for PSIS-LOO.\n+Unlike for chi-square goodness of fit tests, models do not have to be nested for PSIS-LOO to\n+be valid.\n \n \n See also: [`psis_loo`]@ref, [`Psis`]@ref\n \n"
                },
                {
                    "date": 1626981861157,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -13,26 +13,43 @@\n         I <: Integer,\n         VI <: AbstractVector{I},\n     } <: AbstractLoo\n \n-A struct containing the results of leave-one-out cross validation using Pareto smoothed\n-importance sampling.\n+A struct containing the results of jackknife (leave-one-out cross validation) using Pareto \n+smoothed importance sampling.\n \n # Fields\n \n-  - `estimates::KeyedArray`: A `KeyedArray` with two columns (`:Estimate`, `:SE`) and three\n-    rows (`:total_score`, `:overfit`, `:avg_score`). This contains point estimates and\n+  - `estimates::KeyedArray`: A KeyedArray with columns `:total, :se_total, :mean, :se_mean`.\n+    These columns contain sample estimates of the total \n+        - `:loo_est` contains estimates for the total out-of-sample prediction error, as\n+          predicted using the jackknife (leave-one-out CV).\n+        - `:overfit` contains estimates for the total out-of-sample \n     standard errors for the total log score (the sum of all errors); the effective number of \n     parameters (difference between in-sample and out-of-sample predictive accuracy); and the\n     average log-score (Sometimes referred to as the ELPD). See the extended help for more\n     details.\n-  - `pointwise::KeyedArray`: An array of pointwise values\n+  - `pointwise::KeyedArray`: A `KeyedArray` of pointwise estimates with 5 columns --\n+        - `:loo_est` contains the estimated out-of-sample error for this point, as measured\n+          using leave-one-out cross validation.\n+        - `:naive_est` contains the in-sample estimate of error for this point.\n+        - `:overfit` is the difference of \n   - `psis_object::Psis`: A `Psis` object containing the results of Pareto-smoothed \n     importance sampling.\n \n \n # Extended help\n \n+\n+Remember -- all of these quantities are frequentist point estimates! Leave-one-out cross\n+validation provides a mostly-unbiased *estimate* of the out-of-sample prediction error. It \n+does not calculate the \"correct\" answer, and it will not always find the best model.\n+This is especially true if your sample size is small, if you are comparing many different \n+models, or if your model is \"too robust\" and insensitive to small changes in the data.\n+We suggest looking at the [`bayes_cv`]@ref function if you would like a better picture of\n+what these errors might look like.\n+\n+\n The total score depends on the sample size, and summarizes the weight of evidence for or\n against a model. Total scores are on an interval scale, meaning that only differences of\n scores are meaningful. *It is not possible to interpret a total score by looking at it.*\n The total score is not a relative goodness-of-fit statistic (for this, see the average\n@@ -40,9 +57,9 @@\n \n \n The overfit is equal to the difference between the in-sample and out-of-sample predictive\n accuracy. When using the log probability score, it is equal to the \"effective number of\n-parameters\" -- a model with an overfit of 2 has \"about as much overfit\" as a model with 2\n+parameters\" -- a model with an overfit of 2 is \"about as overfit\" as a model with 2\n free parameters and flat priors.\n \n \n The average score is the total score, divided by the sample size. It estimates the expected\n@@ -54,9 +71,9 @@\n Unlike for chi-square goodness of fit tests, models do not have to be nested for PSIS-LOO to\n be valid.\n \n \n-See also: [`psis_loo`]@ref, [`Psis`]@ref\n+See also: [`bayes_cv`]@ref, [`psis_loo`]@ref, [`Psis`]@ref\n \n \"\"\"\n struct PsisLoo{\n     F <: AbstractFloat,\n@@ -96,4 +113,64 @@\n         formatters=ft_printf(\"%5.2f\"),\n         alignment=:r,\n     )\n end\n+\n+\n+\"\"\"\n+    BayesCV{\n+        F <: AbstractFloat,\n+        AF <: AbstractArray{F},\n+        VF <: AbstractVector{F},\n+        I <: Integer,\n+        VI <: AbstractVector{I},\n+    } <: AbstractLoo\n+\n+A struct containing the results of cross-validation using the Bayesian bootstrap.\n+\n+# Fields\n+\n+  - `estimates::KeyedArray`: \n+  - `pointwise::KeyedArray`: An array of pointwise values\n+  - `psis_object::Psis`: A `Psis` object containing the results of Pareto-smoothed \n+    importance sampling.\n+\n+\n+# Extended help\n+\n+The total score depends on the sample size, and summarizes the weight of evidence for or\n+against a model. Total scores are on an interval scale, meaning that only differences of\n+scores are meaningful. *It is not possible to interpret a total score by looking at it.*\n+The total score is not a relative goodness-of-fit statistic (for this, see the average\n+score).\n+\n+\n+The overfit is equal to the difference between the in-sample and out-of-sample predictive\n+accuracy. When using the log probability score, it is equal to the \"effective number of\n+parameters\" -- a model with an overfit of 2 has \"about as much overfit\" as a model with 2\n+free parameters and flat priors.\n+\n+\n+The average score is the total score, divided by the sample size. It estimates the expected\n+log score, i.e. the expectation of the log probability density of observing the next point.\n+The average score is a relative goodness-of-fit statistic which does not depend on sample\n+size. \n+\n+\n+Unlike for chi-square goodness of fit tests, models do not have to be nested for PSIS-LOO to\n+be valid.\n+\n+\n+See also: [`psis_loo`]@ref, [`Psis`]@ref\n+\n+\"\"\"\n+struct BayesBoot{\n+    F <: AbstractFloat,\n+    AF <: AbstractArray{F},\n+    VF <: AbstractVector{F},\n+    I <: Integer,\n+    VI <: AbstractVector{I},\n+} <: AbstractLoo\n+    estimates::KeyedArray\n+    pointwise::KeyedArray\n+    psis_object::Psis{F, AF, VF, I, VI}\n+end\n"
                },
                {
                    "date": 1626981997678,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -43,11 +43,11 @@\n Remember -- all of these quantities are frequentist point estimates! Leave-one-out cross\n validation provides a mostly-unbiased *estimate* of the out-of-sample prediction error. It \n does not calculate the \"correct\" answer, and it will not always find the best model.\n This is especially true if your sample size is small, if you are comparing many different \n-models, or if your model is \"too robust\" and insensitive to small changes in the data.\n-We suggest looking at the [`bayes_cv`]@ref function if you would like a better picture of\n-what these errors might look like.\n+models, or if your model is \"too robust\" and insensitive to small changes in the data \n+(e.g. a Cauchy likelihood). We suggest looking at the [`bayes_cv`]@ref function if you would \n+like a better picture of what these errors might look like.\n \n \n The total score depends on the sample size, and summarizes the weight of evidence for or\n against a model. Total scores are on an interval scale, meaning that only differences of\n"
                },
                {
                    "date": 1626983370541,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -18,22 +18,28 @@\n smoothed importance sampling.\n \n # Fields\n \n-  - `estimates::KeyedArray`: A KeyedArray with columns `:total, :se_total, :mean, :se_mean`.\n-    These columns contain sample estimates of the total \n-        - `:loo_est` contains estimates for the total out-of-sample prediction error, as\n-          predicted using the jackknife (leave-one-out CV).\n-        - `:overfit` contains estimates for the total out-of-sample \n-    standard errors for the total log score (the sum of all errors); the effective number of \n-    parameters (difference between in-sample and out-of-sample predictive accuracy); and the\n-    average log-score (Sometimes referred to as the ELPD). See the extended help for more\n-    details.\n+  - `estimates::KeyedArray`: A KeyedArray with columns `:total, :se_total, :mean, :se_mean`,\n+    and rows `:loo_est, :naive_est, :overfit`. See `# Extended help` for more.\n+      - `:loo_est` contains estimates for the out-of-sample prediction error, as\n+        predicted using the jackknife (LOO-CV).\n+      - `:naive_est` contains estimates of the in-sample prediction error.\n+      - `:overfit` is the difference between the previous two estimators, and estimates \n+        the amount of overfitting. When using the log probability score, it is equal to \n+        the effective number of parameters -- a model with an overfit of 2 is \"about as\n+        overfit\" as a model with 2 independent parameters that have a flat prior.\n   - `pointwise::KeyedArray`: A `KeyedArray` of pointwise estimates with 5 columns --\n-        - `:loo_est` contains the estimated out-of-sample error for this point, as measured\n-          using leave-one-out cross validation.\n-        - `:naive_est` contains the in-sample estimate of error for this point.\n-        - `:overfit` is the difference of \n+      - `:loo_est` contains the estimated out-of-sample error for this point, as measured\n+        using leave-one-out cross validation.\n+      - `:naive_est` contains the in-sample estimate of error for this point.\n+      - `:overfit` is the difference in the two previous estimates.\n+      - `:ess` is the effective sample size, which measures the simulation error caused by \n+        using Monte Carlo estimates. It is *not* related to the actual sample size, and it\n+        does not measure how accurate your predictions are.     \n+      - `:pareto_k` is the estimated value for the parameter `ξ` of the generalized Pareto\n+        distribution. Values above .7 indicate that PSIS has failed to approximate the true\n+        distribution.\n   - `psis_object::Psis`: A `Psis` object containing the results of Pareto-smoothed \n     importance sampling.\n \n \n@@ -44,31 +50,24 @@\n validation provides a mostly-unbiased *estimate* of the out-of-sample prediction error. It \n does not calculate the \"correct\" answer, and it will not always find the best model.\n This is especially true if your sample size is small, if you are comparing many different \n models, or if your model is \"too robust\" and insensitive to small changes in the data \n-(e.g. a Cauchy likelihood). We suggest looking at the [`bayes_cv`]@ref function if you would \n+(e.g. the sample median). We suggest looking at the [`bayes_cv`]@ref function if you would \n like a better picture of what these errors might look like.\n \n \n-The total score depends on the sample size, and summarizes the weight of evidence for or\n+The total score depends on the sample size, and measures the amount of evidence for or\n against a model. Total scores are on an interval scale, meaning that only differences of\n-scores are meaningful. *It is not possible to interpret a total score by looking at it.*\n-The total score is not a relative goodness-of-fit statistic (for this, see the average\n-score).\n+scores are meaningful. It is not possible to interpret a total score by looking at it.\n+The total score is not a goodness-of-fit statistic (for this, see the average score).\n \n \n-The overfit is equal to the difference between the in-sample and out-of-sample predictive\n-accuracy. When using the log probability score, it is equal to the \"effective number of\n-parameters\" -- a model with an overfit of 2 is \"about as overfit\" as a model with 2\n-free parameters and flat priors.\n+The mean score equals the total score divided by the sample size. It is an estimate of the\n+log score. The average score is a relative goodness-of-fit statistic which does not depend \n+on sample size: it tells you how much better one model is than another model, but not how\n+sure you can be that one model is better than another.\n \n \n-The average score is the total score, divided by the sample size. It estimates the expected\n-log score, i.e. the expectation of the log probability density of observing the next point.\n-The average score is a relative goodness-of-fit statistic which does not depend on sample\n-size. \n-\n-\n Unlike for chi-square goodness of fit tests, models do not have to be nested for PSIS-LOO to\n be valid.\n \n \n"
                },
                {
                    "date": 1627054294882,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -2,9 +2,9 @@\n using AxisKeys\n using PrettyTables\n export PsisLoo, AbstractLoo, AbstractLooMethod, PsisLooMethod\n \n-abstract type AbstractLoo end\n+abstract type AbstractCV end\n \n \"\"\"\n     PsisLoo{\n         F <: AbstractFloat,\n@@ -85,9 +85,9 @@\n     pointwise::KeyedArray\n     psis_object::Psis{F, AF, VF, I, VI}\n end\n \n-abstract type AbstractLooMethod end\n+abstract type AbstractCVMethod end\n \n struct PsisLooMethod <: AbstractLooMethod end\n \n function _throw_pareto_k_warning(ξ)\n@@ -127,14 +127,33 @@\n A struct containing the results of cross-validation using the Bayesian bootstrap.\n \n # Fields\n \n-  - `estimates::KeyedArray`: \n-  - `pointwise::KeyedArray`: An array of pointwise values\n-  - `psis_object::Psis`: A `Psis` object containing the results of Pareto-smoothed \n-    importance sampling.\n+- `estimates::KeyedArray`: A KeyedArray with columns `:total, :se_total, :mean, :se_mean`,\n+and rows `:loo_est, :naive_est, :overfit`. See `# Extended help` for more.\n+  - `:loo_est` contains estimates for the out-of-sample prediction error, as\n+    predicted using the jackknife (LOO-CV).\n+  - `:naive_est` contains estimates of the in-sample prediction error.\n+  - `:overfit` is the difference between the previous two estimators, and estimates \n+    the amount of overfitting. When using the log probability score, it is equal to \n+    the effective number of parameters -- a model with an overfit of 2 is \"about as\n+    overfit\" as a model with 2 independent parameters that have a flat prior.\n+- `pointwise::KeyedArray`: A `KeyedArray` of pointwise estimates with 5 columns --\n+  - `:loo_est` contains the estimated out-of-sample error for this point, as measured\n+    using leave-one-out cross validation.\n+  - `:naive_est` contains the in-sample estimate of error for this point.\n+  - `:overfit` is the difference in the two previous estimates.\n+  - `:ess` is the effective sample size, which measures the simulation error caused by \n+    using Monte Carlo estimates. It is *not* related to the actual sample size, and it\n+    does not measure how accurate your predictions are.     \n+  - `:pareto_k` is the estimated value for the parameter `ξ` of the generalized Pareto\n+    distribution. Values above .7 indicate that PSIS has failed to approximate the true\n+    distribution.\n+- `psis_object::Psis`: A `Psis` object containing the results of Pareto-smoothed \n+importance sampling.\n \n \n+\n # Extended help\n \n The total score depends on the sample size, and summarizes the weight of evidence for or\n against a model. Total scores are on an interval scale, meaning that only differences of\n@@ -154,22 +173,36 @@\n The average score is a relative goodness-of-fit statistic which does not depend on sample\n size. \n \n \n-Unlike for chi-square goodness of fit tests, models do not have to be nested for PSIS-LOO to\n-be valid.\n+Unlike for chi-square goodness of fit tests, models do not have to be nested for model\n+comparison with the Bayesian bootstrap.\n \n \n See also: [`psis_loo`]@ref, [`Psis`]@ref\n \n \"\"\"\n-struct BayesBoot{\n+struct BayesCV{\n     F <: AbstractFloat,\n     AF <: AbstractArray{F},\n     VF <: AbstractVector{F},\n     I <: Integer,\n     VI <: AbstractVector{I},\n-} <: AbstractLoo\n+} <: AbstractCV\n     estimates::KeyedArray\n-    pointwise::KeyedArray\n+    posterior::VF\n     psis_object::Psis{F, AF, VF, I, VI}\n end\n+\n+\n+function Base.show(io::IO, ::MIME\"text/plain\", loo_object::BayesCV)\n+    table = loo_object.estimates\n+    _throw_pareto_k_warning(loo_object.pointwise(:pareto_k))\n+    return pretty_table(\n+        table;\n+        compact_printing=false,\n+        header=table.statistic,\n+        row_names=table.criterion,\n+        formatters=ft_printf(\"%5.2f\"),\n+        alignment=:r,\n+    )\n+end\n"
                },
                {
                    "date": 1627066141199,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,23 +1,14 @@\n \n using AxisKeys\n+using KernelDensity\n using PrettyTables\n export PsisLoo, AbstractLoo, AbstractLooMethod, PsisLooMethod\n \n abstract type AbstractCV end\n \n-\"\"\"\n-    PsisLoo{\n-        F <: AbstractFloat,\n-        AF <: AbstractArray{F},\n-        VF <: AbstractVector{F},\n-        I <: Integer,\n-        VI <: AbstractVector{I},\n-    } <: AbstractLoo\n-\n-A struct containing the results of jackknife (leave-one-out cross validation) using Pareto \n-smoothed importance sampling.\n-\n+const POINTWISE_LABELS = (:loo_est, :naive_est, :overfit, :ess, :pareto_k)\n+const CV_DESC = \"\"\"\n # Fields\n \n   - `estimates::KeyedArray`: A KeyedArray with columns `:total, :se_total, :mean, :se_mean`,\n     and rows `:loo_est, :naive_est, :overfit`. See `# Extended help` for more.\n@@ -35,45 +26,58 @@\n       - `:overfit` is the difference in the two previous estimates.\n       - `:ess` is the effective sample size, which measures the simulation error caused by \n         using Monte Carlo estimates. It is *not* related to the actual sample size, and it\n         does not measure how accurate your predictions are.     \n-      - `:pareto_k` is the estimated value for the parameter `ξ` of the generalized Pareto\n-        distribution. Values above .7 indicate that PSIS has failed to approximate the true\n-        distribution.\n+    - `:pareto_k` is the estimated value for the parameter `ξ` of the generalized Pareto\n+      distribution. Values above .7 indicate that PSIS has failed to approximate the true\n+      distribution.\n   - `psis_object::Psis`: A `Psis` object containing the results of Pareto-smoothed \n-    importance sampling.\n+  importance sampling.\n \n \n+\n # Extended help\n \n+The total score depends on the sample size, and summarizes the weight of evidence for or\n+against a model. Total scores are on an interval scale, meaning that only differences of\n+scores are meaningful. *It is not possible to interpret a total score by looking at it.*\n+The total score is not a relative goodness-of-fit statistic (for this, see the average\n+score).\n \n-Remember -- all of these quantities are frequentist point estimates! Leave-one-out cross\n-validation provides a mostly-unbiased *estimate* of the out-of-sample prediction error. It \n-does not calculate the \"correct\" answer, and it will not always find the best model.\n-This is especially true if your sample size is small, if you are comparing many different \n-models, or if your model is \"too robust\" and insensitive to small changes in the data \n-(e.g. the sample median). We suggest looking at the [`bayes_cv`]@ref function if you would \n-like a better picture of what these errors might look like.\n \n+The overfit is equal to the difference between the in-sample and out-of-sample predictive\n+accuracy. When using the log probability score, it is equal to the \"effective number of\n+parameters\" -- a model with an overfit of 2 has \"about as much overfit\" as a model with 2\n+free parameters and flat priors.\n \n-The total score depends on the sample size, and measures the amount of evidence for or\n-against a model. Total scores are on an interval scale, meaning that only differences of\n-scores are meaningful. It is not possible to interpret a total score by looking at it.\n-The total score is not a goodness-of-fit statistic (for this, see the average score).\n \n+The average score is the total score, divided by the sample size. It estimates the expected\n+log score, i.e. the expectation of the log probability density of observing the next point.\n+The average score is a relative goodness-of-fit statistic which does not depend on sample\n+size. \n \n-The mean score equals the total score divided by the sample size. It is an estimate of the\n-log score. The average score is a relative goodness-of-fit statistic which does not depend \n-on sample size: it tells you how much better one model is than another model, but not how\n-sure you can be that one model is better than another.\n \n+Unlike for chi-square goodness of fit tests, models do not have to be nested for model\n+comparison using cross-validation methods.\n+\"\"\"\n \n-Unlike for chi-square goodness of fit tests, models do not have to be nested for PSIS-LOO to\n-be valid.\n \n+\"\"\"\n+    PsisLoo{\n+        F <: AbstractFloat,\n+        AF <: AbstractArray{F},\n+        VF <: AbstractVector{F},\n+        I <: Integer,\n+        VI <: AbstractVector{I},\n+    } <: AbstractLoo\n \n-See also: [`bayes_cv`]@ref, [`psis_loo`]@ref, [`Psis`]@ref\n+A struct containing the results of jackknife (leave-one-out cross validation) using Pareto \n+smoothed importance sampling.\n \n+$CV_DESC\n+\n+See also: [`loo`]@ref, [`bayes_cv`]@ref, [`psis_loo`]@ref, [`Psis`]@ref\n+\n \"\"\"\n struct PsisLoo{\n     F <: AbstractFloat,\n     AF <: AbstractArray{F},\n@@ -82,8 +86,9 @@\n     VI <: AbstractVector{I},\n } <: AbstractLoo\n     estimates::KeyedArray\n     pointwise::KeyedArray\n+    pointwise_density::NamedTuple{POINTWISE_LABELS, UnivariateKDE}\n     psis_object::Psis{F, AF, VF, I, VI}\n end\n \n abstract type AbstractCVMethod end\n@@ -125,60 +130,10 @@\n     } <: AbstractLoo\n \n A struct containing the results of cross-validation using the Bayesian bootstrap.\n \n-# Fields\n+$CV_DESC\n \n-- `estimates::KeyedArray`: A KeyedArray with columns `:total, :se_total, :mean, :se_mean`,\n-and rows `:loo_est, :naive_est, :overfit`. See `# Extended help` for more.\n-  - `:loo_est` contains estimates for the out-of-sample prediction error, as\n-    predicted using the jackknife (LOO-CV).\n-  - `:naive_est` contains estimates of the in-sample prediction error.\n-  - `:overfit` is the difference between the previous two estimators, and estimates \n-    the amount of overfitting. When using the log probability score, it is equal to \n-    the effective number of parameters -- a model with an overfit of 2 is \"about as\n-    overfit\" as a model with 2 independent parameters that have a flat prior.\n-- `pointwise::KeyedArray`: A `KeyedArray` of pointwise estimates with 5 columns --\n-  - `:loo_est` contains the estimated out-of-sample error for this point, as measured\n-    using leave-one-out cross validation.\n-  - `:naive_est` contains the in-sample estimate of error for this point.\n-  - `:overfit` is the difference in the two previous estimates.\n-  - `:ess` is the effective sample size, which measures the simulation error caused by \n-    using Monte Carlo estimates. It is *not* related to the actual sample size, and it\n-    does not measure how accurate your predictions are.     \n-  - `:pareto_k` is the estimated value for the parameter `ξ` of the generalized Pareto\n-    distribution. Values above .7 indicate that PSIS has failed to approximate the true\n-    distribution.\n-- `psis_object::Psis`: A `Psis` object containing the results of Pareto-smoothed \n-importance sampling.\n-\n-\n-\n-# Extended help\n-\n-The total score depends on the sample size, and summarizes the weight of evidence for or\n-against a model. Total scores are on an interval scale, meaning that only differences of\n-scores are meaningful. *It is not possible to interpret a total score by looking at it.*\n-The total score is not a relative goodness-of-fit statistic (for this, see the average\n-score).\n-\n-\n-The overfit is equal to the difference between the in-sample and out-of-sample predictive\n-accuracy. When using the log probability score, it is equal to the \"effective number of\n-parameters\" -- a model with an overfit of 2 has \"about as much overfit\" as a model with 2\n-free parameters and flat priors.\n-\n-\n-The average score is the total score, divided by the sample size. It estimates the expected\n-log score, i.e. the expectation of the log probability density of observing the next point.\n-The average score is a relative goodness-of-fit statistic which does not depend on sample\n-size. \n-\n-\n-Unlike for chi-square goodness of fit tests, models do not have to be nested for model\n-comparison with the Bayesian bootstrap.\n-\n-\n See also: [`psis_loo`]@ref, [`Psis`]@ref\n \n \"\"\"\n struct BayesCV{\n@@ -188,9 +143,10 @@\n     I <: Integer,\n     VI <: AbstractVector{I},\n } <: AbstractCV\n     estimates::KeyedArray\n-    posterior::VF\n+    pointwise::KeyedArray\n+    density::NamedTuple{UnivariateKDE}\n     psis_object::Psis{F, AF, VF, I, VI}\n end\n \n \n"
                },
                {
                    "date": 1627066417157,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -30,9 +30,9 @@\n     - `:pareto_k` is the estimated value for the parameter `ξ` of the generalized Pareto\n       distribution. Values above .7 indicate that PSIS has failed to approximate the true\n       distribution.\n   - `psis_object::Psis`: A `Psis` object containing the results of Pareto-smoothed \n-  importance sampling.\n+    importance sampling.\n \n \n \n # Extended help\n"
                },
                {
                    "date": 1627066423111,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -33,9 +33,8 @@\n   - `psis_object::Psis`: A `Psis` object containing the results of Pareto-smoothed \n     importance sampling.\n \n \n-\n # Extended help\n \n The total score depends on the sample size, and summarizes the weight of evidence for or\n against a model. Total scores are on an interval scale, meaning that only differences of\n"
                },
                {
                    "date": 1627066819074,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -89,9 +89,8 @@\n     pointwise_density::NamedTuple{POINTWISE_LABELS, UnivariateKDE}\n     psis_object::Psis{F, AF, VF, I, VI}\n end\n \n-abstract type AbstractCVMethod end\n \n struct PsisLooMethod <: AbstractLooMethod end\n \n function _throw_pareto_k_warning(ξ)\n"
                },
                {
                    "date": 1627082027309,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -85,10 +85,10 @@\n     VI <: AbstractVector{I},\n } <: AbstractLoo\n     estimates::KeyedArray\n     pointwise::KeyedArray\n-    pointwise_density::NamedTuple{POINTWISE_LABELS, UnivariateKDE}\n     psis_object::Psis{F, AF, VF, I, VI}\n+    subsamples::Vector{Bool}\n end\n \n \n struct PsisLooMethod <: AbstractLooMethod end\n@@ -142,10 +142,10 @@\n     VI <: AbstractVector{I},\n } <: AbstractCV\n     estimates::KeyedArray\n     pointwise::KeyedArray\n-    density::NamedTuple{UnivariateKDE}\n     psis_object::Psis{F, AF, VF, I, VI}\n+    subsamples::Vector{Bool}\n end\n \n \n function Base.show(io::IO, ::MIME\"text/plain\", loo_object::BayesCV)\n"
                },
                {
                    "date": 1627082076201,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -130,9 +130,9 @@\n A struct containing the results of cross-validation using the Bayesian bootstrap.\n \n $CV_DESC\n \n-See also: [`psis_loo`]@ref, [`Psis`]@ref\n+See also: [`bayes_cv`]@ref, [`psis_loo`]@ref, [`psis`]@ref, [`Psis`]@ref, \n \n \"\"\"\n struct BayesCV{\n     F <: AbstractFloat,\n"
                },
                {
                    "date": 1627086383511,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -58,25 +58,53 @@\n Unlike for chi-square goodness of fit tests, models do not have to be nested for model\n comparison using cross-validation methods.\n \"\"\"\n \n+\"\"\"\n+    Psis{V<:AbstractVector{F},I<:Integer} where {F<:AbstractFloat}\n \n+A struct containing the results of Pareto-smoothed importance sampling.\n+\n+# Fields\n+  - `weights`: A vector of smoothed, truncated, and normalized importance sampling weights.\n+  - `pareto_k`: Estimates of the shape parameter `k` of the generalized Pareto distribution.\n+  - `ess`: Estimated effective sample size for each LOO evaluation.\n+  - `tail_len`: Vector indicating how large the \"tail\" is for each observation.\n+  - `dims`: Named tuple of length 2 containing `s` (posterior sample size) and `n` (number\n+    of observations).\n \"\"\"\n+struct Psis{\n+    F<:AbstractFloat,\n+    AF<:AbstractArray{F,3},\n+    VF<:AbstractVector{F},\n+    I<:Integer,\n+    VI<:AbstractVector{I},\n+}\n+    weights::AF\n+    pareto_k::VF\n+    ess::VF\n+    r_eff::VF\n+    tail_len::VI\n+    posterior_sample_size::I\n+    data_size::I\n+end\n+\n+\n+\"\"\"\n     PsisLoo{\n         F <: AbstractFloat,\n         AF <: AbstractArray{F},\n         VF <: AbstractVector{F},\n         I <: Integer,\n         VI <: AbstractVector{I},\n     } <: AbstractLoo\n \n-A struct containing the results of jackknife (leave-one-out cross validation) using Pareto \n+A struct containing the results of jackknife (leave-one-out) cross validation using Pareto \n smoothed importance sampling.\n \n $CV_DESC\n \n See also: [`loo`]@ref, [`bayes_cv`]@ref, [`psis_loo`]@ref, [`Psis`]@ref\n-\n \"\"\"\n struct PsisLoo{\n     F <: AbstractFloat,\n     AF <: AbstractArray{F},\n@@ -130,10 +158,9 @@\n A struct containing the results of cross-validation using the Bayesian bootstrap.\n \n $CV_DESC\n \n-See also: [`bayes_cv`]@ref, [`psis_loo`]@ref, [`psis`]@ref, [`Psis`]@ref, \n-\n+See also: [`bayes_cv`]@ref, [`psis_loo`]@ref, [`psis`]@ref, [`Psis`]@ref\n \"\"\"\n struct BayesCV{\n     F <: AbstractFloat,\n     AF <: AbstractArray{F},\n"
                },
                {
                    "date": 1627139565350,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -114,9 +114,9 @@\n } <: AbstractLoo\n     estimates::KeyedArray\n     pointwise::KeyedArray\n     psis_object::Psis{F, AF, VF, I, VI}\n-    subsamples::Vector{Bool}\n+    score::\n end\n \n \n struct PsisLooMethod <: AbstractLooMethod end\n"
                },
                {
                    "date": 1627140035614,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -114,9 +114,8 @@\n } <: AbstractLoo\n     estimates::KeyedArray\n     pointwise::KeyedArray\n     psis_object::Psis{F, AF, VF, I, VI}\n-    score::\n end\n \n \n struct PsisLooMethod <: AbstractLooMethod end\n"
                },
                {
                    "date": 1627143038607,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,9 +1,8 @@\n \n using AxisKeys\n-using KernelDensity\n using PrettyTables\n-export PsisLoo, AbstractLoo, AbstractLooMethod, PsisLooMethod\n+export PsisLoo, PsisLooMethod\n \n abstract type AbstractCV end\n \n const POINTWISE_LABELS = (:loo_est, :naive_est, :overfit, :ess, :pareto_k)\n@@ -58,8 +57,13 @@\n Unlike for chi-square goodness of fit tests, models do not have to be nested for model\n comparison using cross-validation methods.\n \"\"\"\n \n+\n+###########################\n+### IMPORTANCE SAMPLING ###\n+###########################\n+\n \"\"\"\n     Psis{V<:AbstractVector{F},I<:Integer} where {F<:AbstractFloat}\n \n A struct containing the results of Pareto-smoothed importance sampling.\n@@ -88,16 +92,22 @@\n     data_size::I\n end\n \n \n+##########################\n+#### CROSS VALIDATION ####\n+##########################\n+\n+struct AbstractCV end\n+\n \"\"\"\n     PsisLoo{\n         F <: AbstractFloat,\n         AF <: AbstractArray{F},\n         VF <: AbstractVector{F},\n         I <: Integer,\n         VI <: AbstractVector{I},\n-    } <: AbstractLoo\n+    } <: AbstractCV\n \n A struct containing the results of jackknife (leave-one-out) cross validation using Pareto \n smoothed importance sampling.\n \n@@ -110,28 +120,18 @@\n     AF <: AbstractArray{F},\n     VF <: AbstractVector{F},\n     I <: Integer,\n     VI <: AbstractVector{I},\n-} <: AbstractLoo\n+} <: AbstractCV\n     estimates::KeyedArray\n     pointwise::KeyedArray\n     psis_object::Psis{F, AF, VF, I, VI}\n end\n \n \n-struct PsisLooMethod <: AbstractLooMethod end\n+struct PsisLooMethod <: AbstractCVMethod end\n \n-function _throw_pareto_k_warning(ξ)\n-    if any(ξ .≥ .7)\n-        @warn \"Some Pareto k values are very high (>0.7), indicating that PSIS has \" * \n-        \"failed to approximate the true distribution.\"\n-    elseif any(ξ .≥ .5)\n-        @info \"Some Pareto k values are slightly high (>0.5); some pointwise estimates \" *\n-        \"may be slow to converge or have high variance.\"\n-    end\n-end\n \n-\n function Base.show(io::IO, ::MIME\"text/plain\", loo_object::PsisLoo)\n     table = loo_object.estimates\n     _throw_pareto_k_warning(loo_object.pointwise(:pareto_k))\n     return pretty_table(\n@@ -151,9 +151,9 @@\n         AF <: AbstractArray{F},\n         VF <: AbstractVector{F},\n         I <: Integer,\n         VI <: AbstractVector{I},\n-    } <: AbstractLoo\n+    } <: AbstractCV\n \n A struct containing the results of cross-validation using the Bayesian bootstrap.\n \n $CV_DESC\n@@ -167,17 +167,16 @@\n     I <: Integer,\n     VI <: AbstractVector{I},\n } <: AbstractCV\n     estimates::KeyedArray\n-    pointwise::KeyedArray\n+    resamples::KeyedArray\n     psis_object::Psis{F, AF, VF, I, VI}\n-    subsamples::Vector{Bool}\n end\n \n \n-function Base.show(io::IO, ::MIME\"text/plain\", loo_object::BayesCV)\n-    table = loo_object.estimates\n-    _throw_pareto_k_warning(loo_object.pointwise(:pareto_k))\n+function Base.show(io::IO, ::MIME\"text/plain\", cv_object::BayesCV)\n+    table = cv_object.estimates\n+    _throw_pareto_k_warning(cv_object.resamples(:pareto_k))\n     return pretty_table(\n         table;\n         compact_printing=false,\n         header=table.statistic,\n"
                },
                {
                    "date": 1627143075475,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -2,10 +2,8 @@\n using AxisKeys\n using PrettyTables\n export PsisLoo, PsisLooMethod\n \n-abstract type AbstractCV end\n-\n const POINTWISE_LABELS = (:loo_est, :naive_est, :overfit, :ess, :pareto_k)\n const CV_DESC = \"\"\"\n # Fields\n \n"
                },
                {
                    "date": 1627143305237,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -60,8 +60,20 @@\n ###########################\n ### IMPORTANCE SAMPLING ###\n ###########################\n \n+function _throw_pareto_k_warning(ξ)\n+    if any(ξ .≥ .7)\n+        @warn \"Some Pareto k values are very high (>0.7), indicating that PSIS has \" * \n+        \"failed to approximate the true distribution.\"\n+    elseif any(ξ .≥ .5)\n+        @info \"Some Pareto k values are slightly high (>0.5); some pointwise estimates \" *\n+        \"may be slow to converge or have high variance.\"\n+    end\n+end\n+\n+\n+\n \"\"\"\n     Psis{V<:AbstractVector{F},I<:Integer} where {F<:AbstractFloat}\n \n A struct containing the results of Pareto-smoothed importance sampling.\n@@ -89,9 +101,23 @@\n     posterior_sample_size::I\n     data_size::I\n end\n \n+function Base.show(io::IO, ::MIME\"text/plain\", psis_object::Psis)\n+    table = loo_object.estimates\n+    _throw_pareto_k_warning(loo_object.pointwise(:pareto_k))\n+    return pretty_table(\n+        table;\n+        compact_printing=false,\n+        header=table.statistic,\n+        row_names=table.criterion,\n+        formatters=ft_printf(\"%5.2f\"),\n+        alignment=:r,\n+    )\n+end\n \n+\n+\n ##########################\n #### CROSS VALIDATION ####\n ##########################\n \n"
                },
                {
                    "date": 1627143560868,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -89,4 +89,128 @@\n struct Psis{\n     F<:AbstractFloat,\n     AF<:AbstractArray{F,3},\n     VF<:AbstractVector{F},\n+    I<:Integer,\n+    VI<:AbstractVector{I},\n+}\n+    weights::AF\n+    pareto_k::VF\n+    ess::VF\n+    r_eff::VF\n+    tail_len::VI\n+    posterior_sample_size::I\n+    data_size::I\n+end\n+\n+\n+function Base.show(io::IO, ::MIME\"text/plain\", psis_object::Psis)\n+    table = hcat(psis_object.ess)\n+    post_samples = psis_object.posterior_sample_size\n+    data_size = psis_object.data_size\n+    println(\"Results of PSIS with $post_samples Monte Carlo samples and \" *\n+    \"$data_size data points.\")\n+    _throw_pareto_k_warning(psis_object.pointwise(:pareto_k))\n+    return pretty_table(\n+        table;\n+        compact_printing=false,\n+        header=table.statistic,\n+        row_names=table.criterion,\n+        formatters=ft_printf(\"%5.2f\"),\n+        alignment=:r,\n+    )\n+end\n+\n+\n+\n+##########################\n+#### CROSS VALIDATION ####\n+##########################\n+\n+struct AbstractCV end\n+\n+\"\"\"\n+    PsisLoo{\n+        F <: AbstractFloat,\n+        AF <: AbstractArray{F},\n+        VF <: AbstractVector{F},\n+        I <: Integer,\n+        VI <: AbstractVector{I},\n+    } <: AbstractCV\n+\n+A struct containing the results of jackknife (leave-one-out) cross validation using Pareto \n+smoothed importance sampling.\n+\n+$CV_DESC\n+\n+See also: [`loo`]@ref, [`bayes_cv`]@ref, [`psis_loo`]@ref, [`Psis`]@ref\n+\"\"\"\n+struct PsisLoo{\n+    F <: AbstractFloat,\n+    AF <: AbstractArray{F},\n+    VF <: AbstractVector{F},\n+    I <: Integer,\n+    VI <: AbstractVector{I},\n+} <: AbstractCV\n+    estimates::KeyedArray\n+    pointwise::KeyedArray\n+    psis_object::Psis{F, AF, VF, I, VI}\n+end\n+\n+\n+struct PsisLooMethod <: AbstractCVMethod end\n+\n+\n+function Base.show(io::IO, ::MIME\"text/plain\", loo_object::PsisLoo)\n+    table = loo_object.estimates\n+    _throw_pareto_k_warning(loo_object.pointwise(:pareto_k))\n+    return pretty_table(\n+        table;\n+        compact_printing=false,\n+        header=table.statistic,\n+        row_names=table.criterion,\n+        formatters=ft_printf(\"%5.2f\"),\n+        alignment=:r,\n+    )\n+end\n+\n+\n+\"\"\"\n+    BayesCV{\n+        F <: AbstractFloat,\n+        AF <: AbstractArray{F},\n+        VF <: AbstractVector{F},\n+        I <: Integer,\n+        VI <: AbstractVector{I},\n+    } <: AbstractCV\n+\n+A struct containing the results of cross-validation using the Bayesian bootstrap.\n+\n+$CV_DESC\n+\n+See also: [`bayes_cv`]@ref, [`psis_loo`]@ref, [`psis`]@ref, [`Psis`]@ref\n+\"\"\"\n+struct BayesCV{\n+    F <: AbstractFloat,\n+    AF <: AbstractArray{F},\n+    VF <: AbstractVector{F},\n+    I <: Integer,\n+    VI <: AbstractVector{I},\n+} <: AbstractCV\n+    estimates::KeyedArray\n+    resamples::KeyedArray\n+    psis_object::Psis{F, AF, VF, I, VI}\n+end\n+\n+\n+function Base.show(io::IO, ::MIME\"text/plain\", cv_object::BayesCV)\n+    table = cv_object.estimates\n+    _throw_pareto_k_warning(cv_object.resamples(:pareto_k))\n+    return pretty_table(\n+        table;\n+        compact_printing=false,\n+        header=table.statistic,\n+        row_names=table.criterion,\n+        formatters=ft_printf(\"%5.2f\"),\n+        alignment=:r,\n+    )\n+end\n"
                },
                {
                    "date": 1627143620186,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -213,123 +213,4 @@\n         formatters=ft_printf(\"%5.2f\"),\n         alignment=:r,\n     )\n end\n-    I<:Integer,\n-    VI<:AbstractVector{I},\n-}\n-    weights::AF\n-    pareto_k::VF\n-    ess::VF\n-    r_eff::VF\n-    tail_len::VI\n-    posterior_sample_size::I\n-    data_size::I\n-end\n-\n-function Base.show(io::IO, ::MIME\"text/plain\", psis_object::Psis)\n-    table = loo_object.estimates\n-    _throw_pareto_k_warning(loo_object.pointwise(:pareto_k))\n-    return pretty_table(\n-        table;\n-        compact_printing=false,\n-        header=table.statistic,\n-        row_names=table.criterion,\n-        formatters=ft_printf(\"%5.2f\"),\n-        alignment=:r,\n-    )\n-end\n-\n-\n-\n-##########################\n-#### CROSS VALIDATION ####\n-##########################\n-\n-struct AbstractCV end\n-\n-\"\"\"\n-    PsisLoo{\n-        F <: AbstractFloat,\n-        AF <: AbstractArray{F},\n-        VF <: AbstractVector{F},\n-        I <: Integer,\n-        VI <: AbstractVector{I},\n-    } <: AbstractCV\n-\n-A struct containing the results of jackknife (leave-one-out) cross validation using Pareto \n-smoothed importance sampling.\n-\n-$CV_DESC\n-\n-See also: [`loo`]@ref, [`bayes_cv`]@ref, [`psis_loo`]@ref, [`Psis`]@ref\n-\"\"\"\n-struct PsisLoo{\n-    F <: AbstractFloat,\n-    AF <: AbstractArray{F},\n-    VF <: AbstractVector{F},\n-    I <: Integer,\n-    VI <: AbstractVector{I},\n-} <: AbstractCV\n-    estimates::KeyedArray\n-    pointwise::KeyedArray\n-    psis_object::Psis{F, AF, VF, I, VI}\n-end\n-\n-\n-struct PsisLooMethod <: AbstractCVMethod end\n-\n-\n-function Base.show(io::IO, ::MIME\"text/plain\", loo_object::PsisLoo)\n-    table = loo_object.estimates\n-    _throw_pareto_k_warning(loo_object.pointwise(:pareto_k))\n-    return pretty_table(\n-        table;\n-        compact_printing=false,\n-        header=table.statistic,\n-        row_names=table.criterion,\n-        formatters=ft_printf(\"%5.2f\"),\n-        alignment=:r,\n-    )\n-end\n-\n-\n-\"\"\"\n-    BayesCV{\n-        F <: AbstractFloat,\n-        AF <: AbstractArray{F},\n-        VF <: AbstractVector{F},\n-        I <: Integer,\n-        VI <: AbstractVector{I},\n-    } <: AbstractCV\n-\n-A struct containing the results of cross-validation using the Bayesian bootstrap.\n-\n-$CV_DESC\n-\n-See also: [`bayes_cv`]@ref, [`psis_loo`]@ref, [`psis`]@ref, [`Psis`]@ref\n-\"\"\"\n-struct BayesCV{\n-    F <: AbstractFloat,\n-    AF <: AbstractArray{F},\n-    VF <: AbstractVector{F},\n-    I <: Integer,\n-    VI <: AbstractVector{I},\n-} <: AbstractCV\n-    estimates::KeyedArray\n-    resamples::KeyedArray\n-    psis_object::Psis{F, AF, VF, I, VI}\n-end\n-\n-\n-function Base.show(io::IO, ::MIME\"text/plain\", cv_object::BayesCV)\n-    table = cv_object.estimates\n-    _throw_pareto_k_warning(cv_object.resamples(:pareto_k))\n-    return pretty_table(\n-        table;\n-        compact_printing=false,\n-        header=table.statistic,\n-        row_names=table.criterion,\n-        formatters=ft_printf(\"%5.2f\"),\n-        alignment=:r,\n-    )\n-end\n"
                },
                {
                    "date": 1627172316400,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -196,9 +196,11 @@\n     I <: Integer,\n     VI <: AbstractVector{I},\n } <: AbstractCV\n     estimates::KeyedArray\n+    uncorrected::\n     resamples::KeyedArray\n+    pareto_k::KeyedArray\n     psis_object::Psis{F, AF, VF, I, VI}\n end\n \n \n"
                },
                {
                    "date": 1627172513003,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -2,23 +2,23 @@\n using AxisKeys\n using PrettyTables\n export PsisLoo, PsisLooMethod\n \n-const POINTWISE_LABELS = (:loo_est, :naive_est, :overfit, :ess, :pareto_k)\n+const POINTWISE_LABELS = (:cv_est, :naive_est, :overfit, :ess, :pareto_k)\n const CV_DESC = \"\"\"\n # Fields\n \n   - `estimates::KeyedArray`: A KeyedArray with columns `:total, :se_total, :mean, :se_mean`,\n-    and rows `:loo_est, :naive_est, :overfit`. See `# Extended help` for more.\n-      - `:loo_est` contains estimates for the out-of-sample prediction error, as\n+    and rows `:cv_est, :naive_est, :overfit`. See `# Extended help` for more.\n+      - `:cv_est` contains estimates for the out-of-sample prediction error, as\n         predicted using the jackknife (LOO-CV).\n       - `:naive_est` contains estimates of the in-sample prediction error.\n       - `:overfit` is the difference between the previous two estimators, and estimates \n         the amount of overfitting. When using the log probability score, it is equal to \n         the effective number of parameters -- a model with an overfit of 2 is \"about as\n         overfit\" as a model with 2 independent parameters that have a flat prior.\n   - `pointwise::KeyedArray`: A `KeyedArray` of pointwise estimates with 5 columns --\n-      - `:loo_est` contains the estimated out-of-sample error for this point, as measured\n+      - `:cv_est` contains the estimated out-of-sample error for this point, as measured\n         using leave-one-out cross validation.\n       - `:naive_est` contains the in-sample estimate of error for this point.\n       - `:overfit` is the difference in the two previous estimates.\n       - `:ess` is the effective sample size, which measures the simulation error caused by \n@@ -41,9 +41,9 @@\n \n \n The overfit is equal to the difference between the in-sample and out-of-sample predictive\n accuracy. When using the log probability score, it is equal to the \"effective number of\n-parameters\" -- a model with an overfit of 2 has \"about as much overfit\" as a model with 2\n+parameters\" -- a model with an overfit of 2 is \"about as overfit\" as a model with 2\n free parameters and flat priors.\n \n \n The average score is the total score, divided by the sample size. It estimates the expected\n"
                },
                {
                    "date": 1627233175568,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -196,9 +196,8 @@\n     I <: Integer,\n     VI <: AbstractVector{I},\n } <: AbstractCV\n     estimates::KeyedArray\n-    uncorrected::\n     resamples::KeyedArray\n     pareto_k::KeyedArray\n     psis_object::Psis{F, AF, VF, I, VI}\n end\n"
                },
                {
                    "date": 1627235225246,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -196,9 +196,9 @@\n     I <: Integer,\n     VI <: AbstractVector{I},\n } <: AbstractCV\n     estimates::KeyedArray\n-    resamples::KeyedArray\n+    bootstrap_statistics::KeyedArray\n     pareto_k::KeyedArray\n     psis_object::Psis{F, AF, VF, I, VI}\n end\n \n"
                },
                {
                    "date": 1627235546276,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -196,10 +196,9 @@\n     I <: Integer,\n     VI <: AbstractVector{I},\n } <: AbstractCV\n     estimates::KeyedArray\n-    bootstrap_statistics::KeyedArray\n-    pareto_k::KeyedArray\n+    posteriors::KeyedArray\n     psis_object::Psis{F, AF, VF, I, VI}\n end\n \n \n"
                },
                {
                    "date": 1627236640376,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -125,9 +125,9 @@\n ##########################\n #### CROSS VALIDATION ####\n ##########################\n \n-struct AbstractCV end\n+abstract type AbstractCV end\n \n \"\"\"\n     PsisLoo{\n         F <: AbstractFloat,\n"
                },
                {
                    "date": 1627236831271,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -125,56 +125,21 @@\n ##########################\n #### CROSS VALIDATION ####\n ##########################\n \n+\"\"\"\n+    AbstractCV\n+An abstract type used in cross-validation.\n+\"\"\"\n abstract type AbstractCV end\n \n \"\"\"\n-    PsisLoo{\n-        F <: AbstractFloat,\n-        AF <: AbstractArray{F},\n-        VF <: AbstractVector{F},\n-        I <: Integer,\n-        VI <: AbstractVector{I},\n-    } <: AbstractCV\n-\n-A struct containing the results of jackknife (leave-one-out) cross validation using Pareto \n-smoothed importance sampling.\n-\n-$CV_DESC\n-\n-See also: [`loo`]@ref, [`bayes_cv`]@ref, [`psis_loo`]@ref, [`Psis`]@ref\n+    AbstractCVMethod\n+An abstract type used to dispatch the correct method for cross validation.\n \"\"\"\n-struct PsisLoo{\n-    F <: AbstractFloat,\n-    AF <: AbstractArray{F},\n-    VF <: AbstractVector{F},\n-    I <: Integer,\n-    VI <: AbstractVector{I},\n-} <: AbstractCV\n-    estimates::KeyedArray\n-    pointwise::KeyedArray\n-    psis_object::Psis{F, AF, VF, I, VI}\n-end\n+abstract type AbstractCVMethod end\n \n \n-struct PsisLooMethod <: AbstractCVMethod end\n-\n-\n-function Base.show(io::IO, ::MIME\"text/plain\", loo_object::PsisLoo)\n-    table = loo_object.estimates\n-    _throw_pareto_k_warning(loo_object.pointwise(:pareto_k))\n-    return pretty_table(\n-        table;\n-        compact_printing=false,\n-        header=table.statistic,\n-        row_names=table.criterion,\n-        formatters=ft_printf(\"%5.2f\"),\n-        alignment=:r,\n-    )\n-end\n-\n-\n \"\"\"\n     BayesCV{\n         F <: AbstractFloat,\n         AF <: AbstractArray{F},\n"
                },
                {
                    "date": 1627236911655,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -138,9 +138,66 @@\n \"\"\"\n abstract type AbstractCVMethod end\n \n \n+\n+##########################\n+######## PSIS-LOO ########\n+##########################\n+\n+\n \"\"\"\n+    PsisLoo{\n+        F <: AbstractFloat,\n+        AF <: AbstractArray{F},\n+        VF <: AbstractVector{F},\n+        I <: Integer,\n+        VI <: AbstractVector{I},\n+    } <: AbstractCV\n+\n+A struct containing the results of jackknife (leave-one-out) cross validation using Pareto \n+smoothed importance sampling.\n+\n+$CV_DESC\n+\n+See also: [`loo`]@ref, [`bayes_cv`]@ref, [`psis_loo`]@ref, [`Psis`]@ref\n+\"\"\"\n+struct PsisLoo{\n+    F <: AbstractFloat,\n+    AF <: AbstractArray{F},\n+    VF <: AbstractVector{F},\n+    I <: Integer,\n+    VI <: AbstractVector{I},\n+} <: AbstractCV\n+    estimates::KeyedArray\n+    pointwise::KeyedArray\n+    psis_object::Psis{F, AF, VF, I, VI}\n+end\n+\n+\n+struct PsisLooMethod <: AbstractCVMethod end\n+\n+\n+function Base.show(io::IO, ::MIME\"text/plain\", loo_object::PsisLoo)\n+    table = loo_object.estimates\n+    _throw_pareto_k_warning(loo_object.pointwise(:pareto_k))\n+    return pretty_table(\n+        table;\n+        compact_printing=false,\n+        header=table.statistic,\n+        row_names=table.criterion,\n+        formatters=ft_printf(\"%5.2f\"),\n+        alignment=:r,\n+    )\n+end\n+\n+\n+\n+##########################\n+### BAYESIAN BOOTSTRAP ###\n+##########################\n+\n+\"\"\"\n     BayesCV{\n         F <: AbstractFloat,\n         AF <: AbstractArray{F},\n         VF <: AbstractVector{F},\n"
                },
                {
                    "date": 1627236974020,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -60,20 +60,8 @@\n ###########################\n ### IMPORTANCE SAMPLING ###\n ###########################\n \n-function _throw_pareto_k_warning(ξ)\n-    if any(ξ .≥ .7)\n-        @warn \"Some Pareto k values are very high (>0.7), indicating that PSIS has \" * \n-        \"failed to approximate the true distribution.\"\n-    elseif any(ξ .≥ .5)\n-        @info \"Some Pareto k values are slightly high (>0.5); some pointwise estimates \" *\n-        \"may be slow to converge or have high variance.\"\n-    end\n-end\n-\n-\n-\n \"\"\"\n     Psis{V<:AbstractVector{F},I<:Integer} where {F<:AbstractFloat}\n \n A struct containing the results of Pareto-smoothed importance sampling.\n@@ -102,8 +90,19 @@\n     data_size::I\n end\n \n \n+function _throw_pareto_k_warning(ξ)\n+    if any(ξ .≥ .7)\n+        @warn \"Some Pareto k values are very high (>0.7), indicating that PSIS has \" * \n+        \"failed to approximate the true distribution.\"\n+    elseif any(ξ .≥ .5)\n+        @info \"Some Pareto k values are slightly high (>0.5); some pointwise estimates \" *\n+        \"may be slow to converge or have high variance.\"\n+    end\n+end\n+\n+\n function Base.show(io::IO, ::MIME\"text/plain\", psis_object::Psis)\n     table = hcat(psis_object.ess)\n     post_samples = psis_object.posterior_sample_size\n     data_size = psis_object.data_size\n"
                },
                {
                    "date": 1627263319227,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -178,8 +178,10 @@\n \n function Base.show(io::IO, ::MIME\"text/plain\", loo_object::PsisLoo)\n     table = loo_object.estimates\n     _throw_pareto_k_warning(loo_object.pointwise(:pareto_k))\n+    println(\"Results of PSIS-LOO-CV with $post_samples Monte Carlo samples and \" *\n+    \"$data_size data points.\")\n     return pretty_table(\n         table;\n         compact_printing=false,\n         header=table.statistic,\n@@ -225,8 +227,10 @@\n \n function Base.show(io::IO, ::MIME\"text/plain\", cv_object::BayesCV)\n     table = cv_object.estimates\n     _throw_pareto_k_warning(cv_object.resamples(:pareto_k))\n+    println(\"Results of Bayesian bootstrap CV with $post_samples Monte Carlo samples and \" *\n+    \"$data_size data points.\")\n     return pretty_table(\n         table;\n         compact_printing=false,\n         header=table.statistic,\n"
                },
                {
                    "date": 1627269109397,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,8 +1,8 @@\n \n using AxisKeys\n using PrettyTables\n-export PsisLoo, PsisLooMethod\n+export PsisLoo, PsisLooMethod, Psis\n \n const POINTWISE_LABELS = (:cv_est, :naive_est, :overfit, :ess, :pareto_k)\n const CV_DESC = \"\"\"\n # Fields\n"
                },
                {
                    "date": 1627269130295,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,8 +1,8 @@\n \n using AxisKeys\n using PrettyTables\n-export PsisLoo, PsisLooMethod, Psis\n+export PsisLoo, PsisLooMethod, Psis, BayesCV\n \n const POINTWISE_LABELS = (:cv_est, :naive_est, :overfit, :ess, :pareto_k)\n const CV_DESC = \"\"\"\n # Fields\n"
                },
                {
                    "date": 1627269599937,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -102,19 +102,18 @@\n end\n \n \n function Base.show(io::IO, ::MIME\"text/plain\", psis_object::Psis)\n-    table = hcat(psis_object.ess)\n+    table = hcat(psis_object.pareto_k, psis_object.ess)\n     post_samples = psis_object.posterior_sample_size\n     data_size = psis_object.data_size\n     println(\"Results of PSIS with $post_samples Monte Carlo samples and \" *\n     \"$data_size data points.\")\n     _throw_pareto_k_warning(psis_object.pointwise(:pareto_k))\n     return pretty_table(\n         table;\n         compact_printing=false,\n-        header=table.statistic,\n-        row_names=table.criterion,\n+        header=[:pareto_k, :ess],\n         formatters=ft_printf(\"%5.2f\"),\n         alignment=:r,\n     )\n end\n"
                },
                {
                    "date": 1627269693983,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -141,10 +141,18 @@\n ##########################\n ######## PSIS-LOO ########\n ##########################\n \n+\"\"\"\n+    PsisLooMethod\n \n+Use Pareto-smoothed importance sampling together with leave-one-out cross validation to\n+estimate the out-of-sample predictive accuracy.\n \"\"\"\n+struct PsisLooMethod <: AbstractCVMethod end\n+\n+\n+\"\"\"\n     PsisLoo{\n         F <: AbstractFloat,\n         AF <: AbstractArray{F},\n         VF <: AbstractVector{F},\n@@ -171,9 +179,8 @@\n     psis_object::Psis{F, AF, VF, I, VI}\n end\n \n \n-struct PsisLooMethod <: AbstractCVMethod end\n \n \n function Base.show(io::IO, ::MIME\"text/plain\", loo_object::PsisLoo)\n     table = loo_object.estimates\n"
                },
                {
                    "date": 1627269870573,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -107,9 +107,9 @@\n     post_samples = psis_object.posterior_sample_size\n     data_size = psis_object.data_size\n     println(\"Results of PSIS with $post_samples Monte Carlo samples and \" *\n     \"$data_size data points.\")\n-    _throw_pareto_k_warning(psis_object.pointwise(:pareto_k))\n+    _throw_pareto_k_warning(psis_object.pareto_k)\n     return pretty_table(\n         table;\n         compact_printing=false,\n         header=[:pareto_k, :ess],\n"
                },
                {
                    "date": 1627270219412,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -184,8 +184,10 @@\n \n function Base.show(io::IO, ::MIME\"text/plain\", loo_object::PsisLoo)\n     table = loo_object.estimates\n     _throw_pareto_k_warning(loo_object.pointwise(:pareto_k))\n+    post_samples = loo_object.psis_object.posterior_sample_size\n+    data_size = loo_object.psis_object.data_size\n     println(\"Results of PSIS-LOO-CV with $post_samples Monte Carlo samples and \" *\n     \"$data_size data points.\")\n     return pretty_table(\n         table;\n@@ -232,8 +234,10 @@\n \n \n function Base.show(io::IO, ::MIME\"text/plain\", cv_object::BayesCV)\n     table = cv_object.estimates\n+    post_samples = cv_object.psis_object.posterior_sample_size\n+    data_size = cv_object.psis_object.data_size\n     _throw_pareto_k_warning(cv_object.resamples(:pareto_k))\n     println(\"Results of Bayesian bootstrap CV with $post_samples Monte Carlo samples and \" *\n     \"$data_size data points.\")\n     return pretty_table(\n"
                },
                {
                    "date": 1627342318514,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -22,9 +22,9 @@\n       - `:naive_est` contains the in-sample estimate of error for this point.\n       - `:overfit` is the difference in the two previous estimates.\n       - `:ess` is the effective sample size, which measures the simulation error caused by \n         using Monte Carlo estimates. It is *not* related to the actual sample size, and it\n-        does not measure how accurate your predictions are.     \n+        does not measure how accurate your predictions are.\n     - `:pareto_k` is the estimated value for the parameter `ξ` of the generalized Pareto\n       distribution. Values above .7 indicate that PSIS has failed to approximate the true\n       distribution.\n   - `psis_object::Psis`: A `Psis` object containing the results of Pareto-smoothed \n"
                },
                {
                    "date": 1627342393680,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -20,11 +20,11 @@\n       - `:cv_est` contains the estimated out-of-sample error for this point, as measured\n         using leave-one-out cross validation.\n       - `:naive_est` contains the in-sample estimate of error for this point.\n       - `:overfit` is the difference in the two previous estimates.\n-      - `:ess` is the effective sample size, which measures the simulation error caused by \n-        using Monte Carlo estimates. It is *not* related to the actual sample size, and it\n-        does not measure how accurate your predictions are.\n+      - `:ess` is the effective sample size, which measures the simulation error introduced\n+        by the computer program. It is *not* related to the number of data points collected,\n+        and it does *not* measure how accurate your predictions are.\n     - `:pareto_k` is the estimated value for the parameter `ξ` of the generalized Pareto\n       distribution. Values above .7 indicate that PSIS has failed to approximate the true\n       distribution.\n   - `psis_object::Psis`: A `Psis` object containing the results of Pareto-smoothed \n"
                },
                {
                    "date": 1627495089072,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -236,10 +236,11 @@\n function Base.show(io::IO, ::MIME\"text/plain\", cv_object::BayesCV)\n     table = cv_object.estimates\n     post_samples = cv_object.psis_object.posterior_sample_size\n     data_size = cv_object.psis_object.data_size\n-    _throw_pareto_k_warning(cv_object.resamples(:pareto_k))\n-    println(\"Results of Bayesian bootstrap CV with $post_samples Monte Carlo samples and \" *\n+\n+    _throw_pareto_k_warning(cv_object.psis_object.pareto_k)\n+    println(\"Results of Bayesian bootstrap CV with $post_samples Monte Carlo samples, and \" *\n     \"$data_size data points.\")\n     return pretty_table(\n         table;\n         compact_printing=false,\n"
                },
                {
                    "date": 1627497134944,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -235,13 +235,14 @@\n \n function Base.show(io::IO, ::MIME\"text/plain\", cv_object::BayesCV)\n     table = cv_object.estimates\n     post_samples = cv_object.psis_object.posterior_sample_size\n-    data_size = cv_object.psis_object.data_size\n+    resamples = cv_object.psis_object.data_size\n+    data_size = length(cv_object.posteriors)\n \n     _throw_pareto_k_warning(cv_object.psis_object.pareto_k)\n-    println(\"Results of Bayesian bootstrap CV with $post_samples Monte Carlo samples, and \" *\n-    \"$data_size data points.\")\n+    println(\"Results of Bayesian bootstrap CV with $post_samples Monte Carlo samples, \" *\n+    \"$resamples bootstrap samples, and $data_size data points.\")\n     return pretty_table(\n         table;\n         compact_printing=false,\n         header=table.statistic,\n"
                },
                {
                    "date": 1627497747933,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -229,16 +229,17 @@\n } <: AbstractCV\n     estimates::KeyedArray\n     posteriors::KeyedArray\n     psis_object::Psis{F, AF, VF, I, VI}\n+    data_size::I\n end\n \n \n function Base.show(io::IO, ::MIME\"text/plain\", cv_object::BayesCV)\n     table = cv_object.estimates\n     post_samples = cv_object.psis_object.posterior_sample_size\n     resamples = cv_object.psis_object.data_size\n-    data_size = length(cv_object.posteriors)\n+    data_size = cv_object.data_size\n \n     _throw_pareto_k_warning(cv_object.psis_object.pareto_k)\n     println(\"Results of Bayesian bootstrap CV with $post_samples Monte Carlo samples, \" *\n     \"$resamples bootstrap samples, and $data_size data points.\")\n"
                }
            ],
            "date": 1626484301733,
            "name": "Commit-0",
            "content": "\nusing AxisKeys\nusing PrettyTables\nexport PsisLoo, AbstractLoo, AbstractLooMethod, PsisLooMethod\n\nabstract type AbstractLoo end\nstruct PsisLoo{\n    F <: AbstractFloat,\n    AF <: AbstractArray{F},\n    VF <: AbstractVector{F},\n    I <: Integer,\n    VI <: AbstractVector{I},\n} <: AbstractLoo\n    estimates::KeyedArray\n    pointwise::KeyedArray\n    psis_object::Psis{F, AF, VF, I, VI}\nend\n\nabstract type AbstractLooMethod end\n\nstruct PsisLooMethod <: AbstractLooMethod end\n\n\nfunction Base.show(io::IO, ::MIME\"text/plain\", loo_object::PsisLoo)\n    _throw_pareto_k_warnings(loo_object.pointwise(:pareto_k))\n    table = loo_object.estimates\n    return pretty_table(\n        table;\n        compact_printing=false,\n        header=table.estimate,\n        row_names=table.criterion,\n        formatters=ft_printf(\"%5.2f\"),\n        alignment=:r,\n    )\nend\n"
        }
    ]
}